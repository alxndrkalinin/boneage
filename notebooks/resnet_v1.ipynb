{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TMP=\"/tmp\"\n",
      "env: JOBLIB_TEMP_FOLDER=\"/tmp\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models.densenet import model_urls\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import sparseconvnet.legacy as scn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline\n",
    "%env TMP=\"/tmp\"\n",
    "%env JOBLIB_TEMP_FOLDER=\"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def summary(input_size, model):\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            m_key = '%s-%i' % (class_name, module_idx+1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key]['input_shape'] = list(input[0].size())\n",
    "            summary[m_key]['input_shape'][0] = -1\n",
    "            summary[m_key]['output_shape'] = list(output.size())\n",
    "            summary[m_key]['output_shape'][0] = -1\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, 'weight'):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                if module.weight.requires_grad:\n",
    "                    summary[m_key]['trainable'] = True\n",
    "                else:\n",
    "                    summary[m_key]['trainable'] = False\n",
    "            if hasattr(module, 'bias'):\n",
    "                params +=  torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key]['nb_params'] = params\n",
    "\n",
    "        if not isinstance(module, nn.Sequential) and \\\n",
    "           not isinstance(module, nn.ModuleList) and \\\n",
    "           not (module == model):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    # check if there are multiple inputs to the network\n",
    "    if isinstance(input_size[0], (list, tuple)):\n",
    "        x = [Variable(torch.rand(1,*in_size)) for in_size in input_size]\n",
    "    else:\n",
    "        x = Variable(torch.rand(1,*input_size))\n",
    "\n",
    "    # create properties\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "    # make a forward pass\n",
    "    model(x)\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../data/boneage-training-dataset/'\n",
    "TEST_DIR = '../data/boneage-validation-dataset/'\n",
    "TRAIN_LABEL = '../data/train.csv'\n",
    "TEST_LABEL = '../data/dataset_data_file-validation-gender-fa677c87-bd0d-44a1-92f3-f5966389798b.csv'\n",
    "FILETYPE = '.png'\n",
    "img_scale = 256\n",
    "img_size = 244\n",
    "n_channels = 3\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BoneAgeDataset(Dataset):\n",
    "    \"\"\"Bone Age dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, labels, filetype, img_size, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.filetype = filetype\n",
    "        self.img_size = img_size\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        self.training = True if mode == 'train' else False\n",
    "        self.predicting = True if mode == 'pred' else False\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         print(idx)\n",
    "#         sample = 1.0\n",
    "        img_name = os.path.join(self.root_dir, str(self.labels.iloc[idx]['id']) + self.filetype)\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "#         print(img_name, img.size)\n",
    "        \n",
    "        # randomize thresholding\n",
    "        if self.training:\n",
    "            img = img.point(lambda x: x if x < np.random.randint(200,220) else 0)\n",
    "        else:\n",
    "            img = img.point(lambda x: x if x < 220 else 0)\n",
    "            \n",
    "        # resizing\n",
    "#         print('PIL size:', img.size)\n",
    "        img = np.asarray(img)\n",
    "#         print('Np size: ',img.shape)\n",
    "        if img.shape[1] > img.shape[0]:\n",
    "#             print(img.shape)\n",
    "            img = np.swapaxes(img,0,1)\n",
    "    \n",
    "        img = cv2.resize(img, (img_scale,img_scale))\n",
    "\n",
    "#         img = cv2.resize(img, (img_scale,img_scale+210))\n",
    "#         img = img[210:,:]\n",
    "#         print(img.shape)\n",
    "\n",
    "        # rotation\n",
    "        if self.training:\n",
    "            rot_ang = range(0,360,30)\n",
    "            rot_ang = rot_ang[np.random.randint(0,len(rot_ang))]\n",
    "    #         print(rot_ang)\n",
    "            scale = np.random.uniform(0.8,1.2)\n",
    "    #         print(scale)\n",
    "            rot_mat = cv2.getRotationMatrix2D((img.shape[0]/2,img.shape[1]/2), rot_ang, scale);\n",
    "            img = cv2.warpAffine(img, rot_mat, (img.shape[0],img.shape[1]))\n",
    "        \n",
    "        # randomize thresholding\n",
    "        if self.training:\n",
    "            thresh_block_size = np.random.randint(5,9) // 2 * 2 + 1\n",
    "            thresh_param = np.random.randint(5,9)\n",
    "        else:\n",
    "            thresh_block_size = 7\n",
    "            thresh_param = 7\n",
    "        \n",
    "        img_he = self.clahe.apply(cv2.convertScaleAbs(img[:,:,0]))\n",
    "        img_mask = cv2.adaptiveThreshold(img_he, 1, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,\n",
    "                                         thresh_block_size, thresh_param)\n",
    "        img_ch = img_he * img_mask\n",
    "        \n",
    "        if n_channels == 1:\n",
    "            img = img_ch\n",
    "        elif n_channels == 3:\n",
    "            for i in xrange(img.shape[2]):\n",
    "                img[:,:,i] = img_ch\n",
    "        else:\n",
    "            print('\\n Wrong number of channels \\n')\n",
    "\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "#         print('Img:', img.size)\n",
    "        \n",
    "#         image = cv2.imread(img_name)[:,:,::-1]\n",
    "        gender = self.labels.iloc[idx]['male'].astype(np.int32)\n",
    "        pat_id = self.labels.iloc[idx]['id'].astype(np.int32)\n",
    "        \n",
    "        if not self.predicting:\n",
    "            boneage = self.labels.iloc[idx]['boneage'].astype(np.float32)\n",
    "            label = np.hstack((boneage, gender, pat_id))\n",
    "        else:\n",
    "            label = np.hstack((gender, pat_id))\n",
    "#         print(label)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        sample = {'image': img, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#         transforms.Scale(300),\n",
    "#         transforms.CenterCrop(384),\n",
    "        transforms.RandomSizedCrop(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "#         transforms.Scale(300),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'pred': transforms.Compose([\n",
    "#         transforms.Scale(300),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(TRAIN_LABEL, dtype=np.uint16)\n",
    "labels = labels[labels['male']==1]\n",
    "labels = labels.reset_index()\n",
    "bins = xrange(40)\n",
    "labels['bins'] = np.digitize(labels['boneage'], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=7)\n",
    "# skf = KFold(n_splits=7)\n",
    "splits = []\n",
    "for train, test in skf.split(np.zeros(len(labels)), labels['bins']):\n",
    "    fold_label = {\n",
    "        'train': labels.loc[train, ('id', 'boneage', 'male')],\n",
    "        'val': labels.loc[test, ('id', 'boneage', 'male')]\n",
    "    }\n",
    "    splits.append(fold_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splits[0]['train']['boneage'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splits[0]['val']['boneage'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_label = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_datasets = {x: BoneAgeDataset(TRAIN_DIR, fold_label[x], FILETYPE, img_size, data_transforms[x], x)\n",
    "                  for x in ['train', 'val']}\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=48, shuffle=True, num_workers=16, pin_memory=True)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 3, 244, 244])\n",
      "0 0.221601347671\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample in enumerate(dataloders['val']):\n",
    "    print(i_batch, sample['image'].size())\n",
    "    print(i_batch, sample['image'].mean())\n",
    "#     for i in xrange(sample['image'].size()[0]):\n",
    "#         img = sample['image'][i,0,:,:].numpy()\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img, cmap=plt.cm.gray)\n",
    "    if i_batch == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (resnet): DenseNet (\n",
      "    (features): Sequential (\n",
      "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu0): ReLU (inplace)\n",
      "      (pool0): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "      (denseblock1): _DenseBlock (\n",
      "        (denselayer1): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition1): _Transition (\n",
      "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "      )\n",
      "      (denseblock2): _DenseBlock (\n",
      "        (denselayer1): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition2): _Transition (\n",
      "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "      )\n",
      "      (denseblock3): _DenseBlock (\n",
      "        (denselayer1): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer17): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer18): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer19): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer20): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer21): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer22): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer23): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer24): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer25): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer26): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer27): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer28): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer29): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer30): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer31): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer32): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition3): _Transition (\n",
      "        (norm): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "      )\n",
      "      (denseblock4): _DenseBlock (\n",
      "        (denselayer1): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer17): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer18): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer19): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer20): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer21): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer22): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer23): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer24): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer25): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer26): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer27): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer28): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer29): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer30): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer31): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer32): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (norm5): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (classifier): Sequential (\n",
      "      (0): Dropout (p = 0.5)\n",
      "      (1): Linear (1664 -> 512)\n",
      "      (2): ReLU (inplace)\n",
      "      (3): Dropout (p = 0.5)\n",
      "      (4): Linear (512 -> 128)\n",
      "      (5): ReLU (inplace)\n",
      "      (6): Linear (128 -> 1)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_urls['densenet169'] = model_urls['densenet169'].replace('https://', 'http://')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape=(n_channels, img_size, img_size)):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "#         # inception_v3\n",
    "#         self.bn = nn.BatchNorm2d(input_shape[0])\n",
    "#         resnet = models.inception_v3(pretrained=True)\n",
    "        \n",
    "#         num_ftrs = resnet.fc.in_features\n",
    "#         resnet.fc = nn.Linear(num_ftrs, 1)\n",
    "        \n",
    "#         num_ftrs_aux = resnet.AuxLogits.fc.in_features\n",
    "#         resnet.AuxLogits.fc = nn.Linear(num_ftrs_aux, 1)\n",
    "        \n",
    "#         self.resnet = resnet\n",
    "        \n",
    "        # resnet\n",
    "#         self.bn = nn.BatchNorm2d(input_shape[0])\n",
    "        resnet = models.densenet169(pretrained=True)\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_ftrs = resnet.classifier.in_features\n",
    "        boneage_clf = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        resnet.classifier = boneage_clf\n",
    "        self.resnet = resnet\n",
    "\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Conv2d(input_shape[0], 192, 5, stride=3),\n",
    "#             nn.BatchNorm2d(192),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(192, 160, 1, stride=1),\n",
    "#             nn.BatchNorm2d(160),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(160, 96, 1, stride=1),\n",
    "#             nn.BatchNorm2d(96),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             nn.MaxPool2d(3, stride=2, ceil_mode=True),\n",
    "#             nn.Dropout(),\n",
    "            \n",
    "#             nn.Conv2d(96, 192, 5, stride=2),\n",
    "#             nn.BatchNorm2d(192),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(192, 192, 1, stride=1),\n",
    "#             nn.BatchNorm2d(192),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(192, 192, 1, stride=1),\n",
    "#             nn.BatchNorm2d(192),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             nn.AvgPool2d(3, stride=2, ceil_mode=True),\n",
    "#             nn.Dropout(),\n",
    "        \n",
    "#             nn.Conv2d(192, 192, 3),\n",
    "#             nn.BatchNorm2d(192),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(192, 192, 1, stride=1),\n",
    "#             nn.BatchNorm2d(192),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(192, 1, 1, stride=1),\n",
    "#             nn.BatchNorm2d(1),\n",
    "#             nn.ReLU(inplace=True)\n",
    "                                 \n",
    "# #             nn.AvgPool2d(12, stride=12, ceil_mode=True)\n",
    "#         )\n",
    "#         self.boneage_clf = nn.Sequential(\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(32*32, 512),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(512, 128),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(128, 1)\n",
    "#         )\n",
    "#         self.gender_clf = nn.Sequential(\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(32*32, 512),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(512, 128),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(128, 1)\n",
    "#         )\n",
    "        \n",
    "#         resnet.avgpool = nn.AdaptiveAvgPool2d(2)\n",
    "#         num_ftrs = net.fc.in_features\n",
    "#         net.fc = nn.Linear(num_ftrs, 1)\n",
    "#         self.net = net\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.resnet(x)\n",
    "        \n",
    "#         x = self.net(self.bn(x))\n",
    "#         x = self.net(x)\n",
    "#         print(x.size())\n",
    "#         x = x.view(-1, 32*32)\n",
    "#         g_x = self.gender_clf(x)\n",
    "#         ba_x = self.boneage_clf(x)\n",
    "#         x = F.relu(self.lin128(F.dropout(x)))\n",
    "#         x = self.lin1(F.dropout(x))\n",
    "#         x = self.resnet(self.bn(x))\n",
    "#         return ba_x\n",
    "#         return ba_x, g_x\n",
    "        return x\n",
    "    \n",
    "model = Net([n_channels, img_size, img_size])\n",
    "    \n",
    "# print(summary([3, 640, 640], model))\n",
    "print(model)\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.resnet.classifier.parameters(), lr=lr, weight_decay=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pearsonr(x, y):\n",
    "    x = x.view(-1)\n",
    "    mean_x = torch.mean(x)\n",
    "    mean_y = torch.mean(y)\n",
    "    xm = x.sub(mean_x)\n",
    "    ym = y.sub(mean_y)\n",
    "    r_num = xm.dot(ym)\n",
    "    r_den = torch.norm(xm, 2) * torch.norm(ym, 2)\n",
    "    r_val = r_num / r_den\n",
    "    return r_val\n",
    "\n",
    "def ccc(x, y):\n",
    "#     print('X:', x)\n",
    "    mean_x = torch.mean(x)\n",
    "#     print('Mean x:', mean_x)\n",
    "    mean_y = torch.mean(y)\n",
    "#     print('Mean y:', mean_y)\n",
    "    xm = x.sub(mean_x)\n",
    "    ym = y.sub(mean_y)\n",
    "    xn = xm.pow(2).sum() / xm.size()[0]\n",
    "#     print('Xn:', xn)\n",
    "    yn = ym.pow(2).sum() / ym.size()[0]\n",
    "#     print('Yn:', yn)\n",
    "    xydot = ym.dot(xm.view(-1))\n",
    "#     print('XYdot:', xydot)\n",
    "\n",
    "    ccc_num = 2 * xydot / xm.size()[0]\n",
    "#     print('CCC num:', ccc_num)\n",
    "    ccc_den = xn + yn + torch.pow(mean_x.sub(mean_y), 2)\n",
    "#     print('CCC den:', ccc_den)\n",
    "\n",
    "    ccc = ccc_num / ccc_den\n",
    "    return ccc\n",
    "    \n",
    "\n",
    "def train(epoch, train_loader):\n",
    "    since = time.time()\n",
    "    exp_lr_scheduler.step()\n",
    "    model.train()\n",
    "    \n",
    "    train_boneage_loss = 0\n",
    "    train_gender_loss = 0\n",
    "    train_loss = 0\n",
    "    train_ccc = 0\n",
    "    num_samp = len(train_loader.dataset)\n",
    "    \n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ba_output = model(data)\n",
    "        \n",
    "        # 2 heads MTL output\n",
    "#         ba_output, g_output = model(data)\n",
    "#         print(output1)\n",
    "#         print(output2)\n",
    "        \n",
    "#         for i in xrange(output.size[0]):\n",
    "#             if output[i,1] > 0.5:\n",
    "#                 output[i,0] = (output[i,0] // 6) * 6\n",
    "#             else:\n",
    "#                 output[i,0] = (output[i,0] // 2) * 2\n",
    "\n",
    "#         boneage_out = torch.round(output[:,0].div(6)).mul(6)\n",
    "#         boneage_out = output[:,0]\n",
    "\n",
    "#         boneage_loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "#         train_boneage_loss += boneage_loss.data[0]\n",
    "        boneage_loss = F.smooth_l1_loss(ba_output.view(-1), target[:,0])\n",
    "        train_boneage_loss += boneage_loss.data[0]\n",
    "        \n",
    "#         gender_loss = F.binary_cross_entropy_with_logits(g_output.view(-1), target[:,1])\n",
    "#         train_gender_loss += gender_loss.data[0]\n",
    "        \n",
    "#         loss = 0.75 * boneage_loss + 0.25 * gender_loss\n",
    "        loss = boneage_loss\n",
    "#         loss = gender_loss\n",
    "#         loss = F.l1_loss(output1.view(-1), target[:,0]) + F.l1_loss(output2.view(-1), target[:,0])\n",
    "#         loss = 0.8 * F.l1_loss(output.view(-1), target[:,0]) + 0.2 * F.binary_cross_entropy(F.sigmoid(output.view(-1)), target[:,1])\n",
    "#         loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "        \n",
    "        train_loss += loss.data[0]\n",
    "#         c = ccc(boneage_out, target[:,0])\n",
    "        c = ccc(ba_output, target[:,0])\n",
    "        train_ccc += c.data.cpu().numpy()[0]\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % (1000 // len(target)) == 0:\n",
    "#     print('Train ep: {} [{}/{} ({:.0f}%)]\\tBoneAge Loss: {:.4f}\\tGender Loss: {:.4f}\\t Loss: {:.4f}\\tCCC: {:.4f}'.format(\n",
    "#         epoch, batch_idx * len(data), num_samp,\n",
    "#         100. * batch_idx / num_samp, train_boneage_loss / num_samp,\n",
    "#         train_gender_loss / num_samp, train_loss / num_samp,\n",
    "#         train_ccc / num_samp))\n",
    "    \n",
    "    print('\\nTrain Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.4f}\\tCCC: {:.4f}'.format(\n",
    "        epoch, batch_idx * len(data), num_samp,\n",
    "        100. * batch_idx / num_samp, train_loss / num_samp, train_ccc / num_samp))\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "def test(test_loader):\n",
    "    since = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    test_avg_gender = 0\n",
    "    test_boneage_loss = 0\n",
    "    test_boneage_l1_loss = 0\n",
    "    test_boneage_round_loss = 0\n",
    "    test_boneage_round_loss_2 = 0\n",
    "    test_boneage_round_loss_6 = 0\n",
    "    test_gender_loss = 0\n",
    "    test_loss = 0\n",
    "    test_ccc = 0\n",
    "    test_pearsonr = 0\n",
    "    \n",
    "    num_samp = len(test_loader.dataset)\n",
    "    for sample in test_loader:\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "\n",
    "#         test_avg_gender += sample['label'][:,1].sum()\n",
    "        ba_output = model(data)\n",
    "        \n",
    "        # 2 heads MTL output\n",
    "#         ba_output, g_output = model(data)\n",
    "#         print(ba_output)\n",
    "        \n",
    "#         print(output.size())\n",
    "#         boneage_out = torch.round(output[:,0].div(6)).mul(6)\n",
    "#         boneage_out = output[:,0]\n",
    "#         print(boneage_out)\n",
    "#         print(target[:,0])\n",
    "#         boneage_loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "\n",
    "        boneage_loss = F.smooth_l1_loss(ba_output.view(-1), target[:,0])\n",
    "        boneage_l1_loss = F.l1_loss(ba_output.view(-1), target[:,0])\n",
    "# #         print(boneage_loss)\n",
    "        boneage_round_loss = F.l1_loss(torch.round(ba_output.view(-1)), target[:,0])\n",
    "# #         print(boneage_round_loss)\n",
    "        boneage_round_loss_2 = F.l1_loss(torch.round(ba_output.view(-1).div(2)).mul(2), target[:,0])\n",
    "# #         print(boneage_round_loss_2)\n",
    "        boneage_round_loss_6 = F.l1_loss(torch.round(ba_output.view(-1).div(6)).mul(6), target[:,0])\n",
    "# #         print(boneage_round_loss_6)\n",
    "        \n",
    "        test_boneage_loss += boneage_loss.data[0]\n",
    "        test_boneage_l1_loss += boneage_l1_loss.data[0]\n",
    "        test_boneage_round_loss += boneage_round_loss.data[0]\n",
    "        test_boneage_round_loss_2 += boneage_round_loss_2.data[0]\n",
    "        test_boneage_round_loss_6 += boneage_round_loss_6.data[0]\n",
    "    \n",
    "#         print(test_boneage_loss)\n",
    "#         gender_loss = F.binary_cross_entropy_with_logits(g_output.view(-1), target[:,1])\n",
    "#         test_gender_loss += gender_loss.data[0]\n",
    "\n",
    "#         loss = 0.75 * boneage_loss + 0.25 * gender_loss\n",
    "        loss = boneage_loss\n",
    "#         loss = 0.8 * F.l1_loss(output.view(-1), target[:,0]) + 0.2 * F.binary_cross_entropy(F.sigmoid(output.view(-1)), target[:,1])\n",
    "#         loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "\n",
    "        test_loss += loss.data[0]\n",
    "#         c = ccc(boneage_out, target[:,0])\n",
    "        c = ccc(ba_output, target[:,0])\n",
    "        r = pearsonr(ba_output, target[:,0])\n",
    "        test_ccc += c.data.cpu().numpy()[0]\n",
    "        test_pearsonr += r.data.cpu().numpy()[0]\n",
    "\n",
    "    print('\\nTest set: BoneAge loss: {:.4f}, loss: {:.4f}, CCC: {:.4f}, R: {:.4f}'.format(\n",
    "        test_boneage_loss / num_samp, test_loss / num_samp, test_ccc / num_samp, test_pearsonr / num_samp))\n",
    "    print('Test set: L1 loss: {:.4f},Round loss: {:.4f}, Round2 loss: {:.4f}, Round6: {:.4f}, Gender: {:.4f}'.format(\n",
    "        test_boneage_l1_loss / num_samp, test_boneage_round_loss / num_samp, test_boneage_round_loss_2 / num_samp,\n",
    "        test_boneage_round_loss_6 / num_samp, test_avg_gender / num_samp))\n",
    "    \n",
    "#     print('\\nTest set: Avg loss: {:.4f} CCC: {:.4f}\\n'.format(\n",
    "#         test_loss / num_samp, test_ccc / num_samp))\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return test_boneage_l1_loss / num_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 1 [3276/5842 (3%)]\t Loss: 1.2770\tCCC: 0.0014\n",
      "Training complete in 0m 25s\n",
      "\n",
      "Test set: BoneAge loss: 1.0621, loss: 1.0621, CCC: 0.0025, R: 0.0050\n",
      "Test set: L1 loss: 1.0777,Round loss: 1.0776, Round2 loss: 1.0778, Round6: 1.0770, Gender: 0.0000\n",
      "Training complete in 0m 5s\n",
      "\n",
      "\n",
      "Train Epoch: 2 [3276/5842 (3%)]\t Loss: 1.0101\tCCC: 0.0074\n",
      "Training complete in 0m 25s\n",
      "\n",
      "Test set: BoneAge loss: 1.0462, loss: 1.0462, CCC: 0.0051, R: 0.0110\n",
      "Test set: L1 loss: 1.0617,Round loss: 1.0615, Round2 loss: 1.0622, Round6: 1.0615, Gender: 0.0000\n",
      "Training complete in 0m 5s\n",
      "\n",
      "\n",
      "Train Epoch: 3 [3276/5842 (3%)]\t Loss: 0.9912\tCCC: 0.0092\n",
      "Training complete in 0m 25s\n",
      "\n",
      "Test set: BoneAge loss: 0.9630, loss: 0.9630, CCC: 0.0073, R: 0.0131\n",
      "Test set: L1 loss: 0.9785,Round loss: 0.9784, Round2 loss: 0.9778, Round6: 0.9774, Gender: 0.0000\n",
      "Training complete in 0m 5s\n",
      "\n",
      "\n",
      "Train Epoch: 4 [3276/5842 (3%)]\t Loss: 0.9865\tCCC: 0.0103\n",
      "Training complete in 0m 25s\n",
      "\n",
      "Test set: BoneAge loss: 0.9369, loss: 0.9369, CCC: 0.0080, R: 0.0144\n",
      "Test set: L1 loss: 0.9524,Round loss: 0.9523, Round2 loss: 0.9525, Round6: 0.9524, Gender: 0.0000\n",
      "Training complete in 0m 6s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 4 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: BoneAge loss: 1.0060, loss: 1.0060, CCC: 0.0001, R: 0.0010\n",
      "Test set: L1 loss: 1.0165,Round loss: 1.0161, Round2 loss: 1.0191, Round6: 1.0205, Gender: 0.0000\n",
      "Training complete in 0m 6s\n",
      "\n",
      "\n",
      "Train Epoch: 1 [4114/5842 (2%)]\t Loss: 0.7732\tCCC: 0.0009\n",
      "Training complete in 1m 0s\n",
      "\n",
      "Test set: BoneAge loss: 0.8862, loss: 0.8862, CCC: 0.0000, R: 0.0003\n",
      "Test set: L1 loss: 0.8967,Round loss: 0.8962, Round2 loss: 0.8964, Round6: 0.9071, Gender: 0.0000\n",
      "Training complete in 0m 6s\n",
      "\n",
      "Saved model weights.\n",
      "\n",
      "Train Epoch: 2 [4114/5842 (2%)]\t Loss: 0.7367\tCCC: 0.0018\n",
      "Training complete in 1m 1s\n",
      "\n",
      "Test set: BoneAge loss: 0.8761, loss: 0.8761, CCC: -0.0027, R: -0.0036\n",
      "Test set: L1 loss: 0.8866,Round loss: 0.8864, Round2 loss: 0.8868, Round6: 0.8865, Gender: 0.0000\n",
      "Training complete in 0m 6s\n",
      "\n",
      "Saved model weights.\n",
      "\n",
      "Train Epoch: 3 [4114/5842 (2%)]\t Loss: 0.7293\tCCC: 0.0021\n",
      "Training complete in 1m 1s\n",
      "\n",
      "Test set: BoneAge loss: 0.8193, loss: 0.8193, CCC: 0.0011, R: 0.0035\n",
      "Test set: L1 loss: 0.8298,Round loss: 0.8292, Round2 loss: 0.8307, Round6: 0.8308, Gender: 0.0000\n",
      "Training complete in 0m 6s\n",
      "\n",
      "Saved model weights.\n",
      "\n",
      "Train Epoch: 4 [4114/5842 (2%)]\t Loss: 0.7371\tCCC: 0.0029\n",
      "Training complete in 1m 1s\n",
      "\n",
      "Test set: BoneAge loss: 0.7376, loss: 0.7376, CCC: 0.0003, R: 0.0007\n",
      "Test set: L1 loss: 0.7481,Round loss: 0.7482, Round2 loss: 0.7488, Round6: 0.7462, Gender: 0.0000\n",
      "Training complete in 0m 6s\n",
      "\n",
      "Saved model weights.\n",
      "\n",
      "Train Epoch: 5 [4114/5842 (2%)]\t Loss: 0.7040\tCCC: 0.0035\n",
      "Training complete in 1m 1s\n",
      "\n",
      "Test set: BoneAge loss: 2.0437, loss: 2.0437, CCC: -0.0027, R: -0.0053\n",
      "Test set: L1 loss: 2.0543,Round loss: 2.0543, Round2 loss: 2.0548, Round6: 2.0538, Gender: 0.0000\n",
      "Training complete in 0m 6s\n",
      "\n",
      "\n",
      "Train Epoch: 6 [4114/5842 (2%)]\t Loss: 0.6984\tCCC: 0.0040\n",
      "Training complete in 1m 1s\n",
      "\n",
      "Test set: BoneAge loss: 0.7297, loss: 0.7297, CCC: 0.0049, R: 0.0060\n",
      "Test set: L1 loss: 0.7402,Round loss: 0.7401, Round2 loss: 0.7407, Round6: 0.7407, Gender: 0.0000\n",
      "Training complete in 0m 6s\n",
      "\n",
      "Saved model weights.\n",
      "\n",
      "Train Epoch: 7 [4114/5842 (2%)]\t Loss: 0.7008\tCCC: 0.0042\n",
      "Training complete in 1m 1s\n",
      "\n",
      "Test set: BoneAge loss: 0.7385, loss: 0.7385, CCC: 0.0023, R: 0.0038\n",
      "Test set: L1 loss: 0.7490,Round loss: 0.7491, Round2 loss: 0.7488, Round6: 0.7498, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "\n",
      "Train Epoch: 8 [4114/5842 (2%)]\t Loss: 0.6934\tCCC: 0.0044\n",
      "Training complete in 1m 2s\n",
      "\n",
      "Test set: BoneAge loss: 0.7460, loss: 0.7460, CCC: 0.0038, R: 0.0049\n",
      "Test set: L1 loss: 0.7566,Round loss: 0.7570, Round2 loss: 0.7560, Round6: 0.7559, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "\n",
      "Train Epoch: 9 [4114/5842 (2%)]\t Loss: 0.6928\tCCC: 0.0049\n",
      "Training complete in 1m 2s\n",
      "\n",
      "Test set: BoneAge loss: 0.6712, loss: 0.6712, CCC: 0.0038, R: 0.0060\n",
      "Test set: L1 loss: 0.6817,Round loss: 0.6819, Round2 loss: 0.6824, Round6: 0.6839, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "Saved model weights.\n",
      "\n",
      "Train Epoch: 10 [4114/5842 (2%)]\t Loss: 0.6780\tCCC: 0.0055\n",
      "Training complete in 1m 2s\n",
      "\n",
      "Test set: BoneAge loss: 0.7386, loss: 0.7386, CCC: 0.0062, R: 0.0082\n",
      "Test set: L1 loss: 0.7492,Round loss: 0.7494, Round2 loss: 0.7490, Round6: 0.7469, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "\n",
      "Train Epoch: 11 [4114/5842 (2%)]\t Loss: 0.6802\tCCC: 0.0064\n",
      "Training complete in 1m 2s\n",
      "\n",
      "Test set: BoneAge loss: 0.7431, loss: 0.7431, CCC: 0.0048, R: 0.0067\n",
      "Test set: L1 loss: 0.7536,Round loss: 0.7535, Round2 loss: 0.7527, Round6: 0.7541, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "\n",
      "Train Epoch: 12 [4114/5842 (2%)]\t Loss: 0.6476\tCCC: 0.0070\n",
      "Training complete in 1m 2s\n",
      "\n",
      "Test set: BoneAge loss: 0.8504, loss: 0.8504, CCC: 0.0042, R: 0.0050\n",
      "Test set: L1 loss: 0.8609,Round loss: 0.8610, Round2 loss: 0.8614, Round6: 0.8592, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "\n",
      "Train Epoch: 13 [4114/5842 (2%)]\t Loss: 0.6358\tCCC: 0.0081\n",
      "Training complete in 1m 2s\n",
      "\n",
      "Test set: BoneAge loss: 0.8953, loss: 0.8953, CCC: 0.0030, R: 0.0034\n",
      "Test set: L1 loss: 0.9059,Round loss: 0.9059, Round2 loss: 0.9059, Round6: 0.9058, Gender: 0.0000\n",
      "Training complete in 0m 6s\n",
      "\n",
      "\n",
      "Train Epoch: 14 [4114/5842 (2%)]\t Loss: 0.6292\tCCC: 0.0083\n",
      "Training complete in 1m 1s\n",
      "\n",
      "Test set: BoneAge loss: 0.6781, loss: 0.6781, CCC: 0.0048, R: 0.0073\n",
      "Test set: L1 loss: 0.6886,Round loss: 0.6885, Round2 loss: 0.6885, Round6: 0.6873, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "\n",
      "Train Epoch: 15 [4114/5842 (2%)]\t Loss: 0.6237\tCCC: 0.0088\n",
      "Training complete in 1m 2s\n",
      "\n",
      "Test set: BoneAge loss: 0.7028, loss: 0.7028, CCC: 0.0062, R: 0.0070\n",
      "Test set: L1 loss: 0.7133,Round loss: 0.7133, Round2 loss: 0.7140, Round6: 0.7114, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "\n",
      "Train Epoch: 16 [4114/5842 (2%)]\t Loss: 0.6166\tCCC: 0.0086\n",
      "Training complete in 1m 1s\n",
      "\n",
      "Test set: BoneAge loss: 0.6957, loss: 0.6957, CCC: 0.0025, R: 0.0050\n",
      "Test set: L1 loss: 0.7063,Round loss: 0.7064, Round2 loss: 0.7068, Round6: 0.7053, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "\n",
      "Train Epoch: 17 [4114/5842 (2%)]\t Loss: 0.6083\tCCC: 0.0094\n",
      "Training complete in 1m 2s\n",
      "\n",
      "Test set: BoneAge loss: 0.7964, loss: 0.7964, CCC: 0.0045, R: 0.0057\n",
      "Test set: L1 loss: 0.8070,Round loss: 0.8072, Round2 loss: 0.8068, Round6: 0.8023, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "\n",
      "Train Epoch: 18 [4114/5842 (2%)]\t Loss: 0.6045\tCCC: 0.0094\n",
      "Training complete in 1m 1s\n",
      "\n",
      "Test set: BoneAge loss: 0.7379, loss: 0.7379, CCC: 0.0061, R: 0.0068\n",
      "Test set: L1 loss: 0.7484,Round loss: 0.7485, Round2 loss: 0.7485, Round6: 0.7478, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "\n",
      "Train Epoch: 19 [4114/5842 (2%)]\t Loss: 0.5874\tCCC: 0.0100\n",
      "Training complete in 1m 2s\n",
      "\n",
      "Test set: BoneAge loss: 0.9742, loss: 0.9742, CCC: 0.0044, R: 0.0058\n",
      "Test set: L1 loss: 0.9847,Round loss: 0.9851, Round2 loss: 0.9848, Round6: 0.9856, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "\n",
      "Train Epoch: 20 [4114/5842 (2%)]\t Loss: 0.5928\tCCC: 0.0099\n",
      "Training complete in 1m 1s\n",
      "\n",
      "Test set: BoneAge loss: 0.7131, loss: 0.7131, CCC: 0.0055, R: 0.0070\n",
      "Test set: L1 loss: 0.7237,Round loss: 0.7234, Round2 loss: 0.7241, Round6: 0.7233, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "best_loss = test(dataloders['val'])\n",
    "best_model_wts = model.state_dict()\n",
    "\n",
    "lr = 0.01\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "for epoch in range(1, 20 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            epoch_val_loss = test(dataloders[phase])\n",
    "            if epoch_val_loss < best_loss:\n",
    "                best_loss = epoch_val_loss\n",
    "                best_model_wts = model.state_dict()\n",
    "                print('Saved model weights.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 1 [4114/5842 (2%)]\t Loss: 0.5961\tCCC: 0.0098\n",
      "Training complete in 0m 60s\n",
      "\n",
      "Test set: BoneAge loss: 0.7575, loss: 0.7575, CCC: 0.0052, R: 0.0063\n",
      "Test set: L1 loss: 0.7681,Round loss: 0.7686, Round2 loss: 0.7682, Round6: 0.7636, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n",
      "\n",
      "Train Epoch: 2 [4114/5842 (2%)]\t Loss: 0.5839\tCCC: 0.0105\n",
      "Training complete in 1m 1s\n",
      "\n",
      "Test set: BoneAge loss: 0.7077, loss: 0.7077, CCC: 0.0070, R: 0.0080\n",
      "Test set: L1 loss: 0.7183,Round loss: 0.7181, Round2 loss: 0.7186, Round6: 0.7183, Gender: 0.0000\n",
      "Training complete in 0m 7s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "for epoch in range(1, 390 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            epoch_val_loss = test(dataloders[phase])\n",
    "            if epoch_val_loss < best_loss:\n",
    "                best_loss = epoch_val_loss\n",
    "                best_model_wts = model.state_dict()\n",
    "                print('Saved model weights.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(dataloders['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/10-4-2222-resnet50-0fold7-male-0181-0207.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../models/10-3-0320-nin-0fold-083-116.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict(predict_loader):\n",
    "    model.eval()\n",
    "    pred_gender_loss = 0\n",
    "    predictions = []\n",
    "    \n",
    "    num_samp = len(predict_loader.dataset)\n",
    "    for sample in predict_loader:\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "\n",
    "        ba_output, g_output = model(data)\n",
    "    \n",
    "#         print(test_boneage_loss)\n",
    "        gender_loss = F.binary_cross_entropy_with_logits(g_output.view(-1), target[:,0])\n",
    "        pred_gender_loss += gender_loss.data[0]\n",
    "        \n",
    "        pred_labels = target[:,1].data.cpu().numpy()\n",
    "#         print(pred_labels.shape)\n",
    "        pred_bonage = ba_output.view(-1).data.cpu().numpy()\n",
    "#         print(pred_bonage.shape)\n",
    "        \n",
    "        predictions.append(np.column_stack((pred_labels, pred_bonage)))\n",
    "\n",
    "    print('\\nPrediction Gender loss: {:.4f}'.format(pred_gender_loss / num_samp))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_labels = pd.read_csv(TEST_LABEL, dtype=int)\n",
    "pred_labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_image_dataset = BoneAgeDataset(TEST_DIR, pred_labels, FILETYPE, img_size, data_transforms['pred'], 'pred')\n",
    "pred_dataloder = torch.utils.data.DataLoader(pred_image_dataset, batch_size=32, shuffle=True, num_workers=24,\n",
    "                                             pin_memory=True)\n",
    "pred_dataset_size = len(pred_image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i_batch, sample in enumerate(pred_dataloder):\n",
    "    print(i_batch, sample['image'].size())\n",
    "    print(i_batch, sample['image'].mean())\n",
    "#     for i in xrange(sample['image'].size()[0]):\n",
    "#         img = sample['image'][i,0,:,:].numpy()\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img, cmap=plt.cm.gray)\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = predict(pred_dataloder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_preds_df = pd.DataFrame(np.vstack(tuple(preds)), columns=('id', 'boneage')).sort_values('id')\n",
    "all_preds_df['id'] = all_preds_df['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_preds_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_preds_df.to_csv('../sub/10-3-0707-nin-0fold-083-116.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
