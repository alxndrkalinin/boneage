{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TMP=\"/tmp\"\n",
      "env: JOBLIB_TEMP_FOLDER=\"/tmp\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models.inception import model_urls\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import sparseconvnet.legacy as scn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline\n",
    "%env TMP=\"/tmp\"\n",
    "%env JOBLIB_TEMP_FOLDER=\"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary(input_size, model):\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            m_key = '%s-%i' % (class_name, module_idx+1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key]['input_shape'] = list(input[0].size())\n",
    "            summary[m_key]['input_shape'][0] = -1\n",
    "            summary[m_key]['output_shape'] = list(output.size())\n",
    "            summary[m_key]['output_shape'][0] = -1\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, 'weight'):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                if module.weight.requires_grad:\n",
    "                    summary[m_key]['trainable'] = True\n",
    "                else:\n",
    "                    summary[m_key]['trainable'] = False\n",
    "            if hasattr(module, 'bias'):\n",
    "                params +=  torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key]['nb_params'] = params\n",
    "\n",
    "        if not isinstance(module, nn.Sequential) and \\\n",
    "           not isinstance(module, nn.ModuleList) and \\\n",
    "           not (module == model):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    # check if there are multiple inputs to the network\n",
    "    if isinstance(input_size[0], (list, tuple)):\n",
    "        x = [Variable(torch.rand(1,*in_size)) for in_size in input_size]\n",
    "    else:\n",
    "        x = Variable(torch.rand(1,*input_size))\n",
    "\n",
    "    # create properties\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "    # make a forward pass\n",
    "    model(x)\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../data/boneage-training-dataset/'\n",
    "TRAIN_LABEL = '../data/train.csv'\n",
    "FILETYPE = '.png'\n",
    "img_scale = 840\n",
    "img_size = 640\n",
    "n_channels = 1\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BoneAgeDataset(Dataset):\n",
    "    \"\"\"Bone Age dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, labels, filetype, img_size, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.filetype = filetype\n",
    "        self.img_size = img_size\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        self.training = True if mode == 'train' else False\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, str(self.labels.iloc[idx]['id']) + self.filetype)\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        # randomize thresholding\n",
    "        if self.training:\n",
    "            img = img.point(lambda x: x if x < np.random.randint(180,220) else 0)\n",
    "        else:\n",
    "            img = img.point(lambda x: x if x < 200 else 0)\n",
    "            \n",
    "        # resizing\n",
    "#         print('PIL size:', img.size)\n",
    "        img = np.asarray(img)\n",
    "#         print('Np size: ',img.shape)\n",
    "        if img.shape[1] > img.shape[0]:\n",
    "#             print(img.shape)\n",
    "            img = np.swapaxes(img,0,1)\n",
    "        img = cv2.resize(img, (img_scale,img_scale+210))\n",
    "        img = img[210:,:]\n",
    "#         print(img.shape)\n",
    "\n",
    "        # rotation\n",
    "        if self.training:\n",
    "            rot_ang = range(0,360,30)\n",
    "            rot_ang = rot_ang[np.random.randint(0,len(rot_ang))]\n",
    "    #         print(rot_ang)\n",
    "            scale = np.random.uniform(0.8,1.2)\n",
    "    #         print(scale)\n",
    "            rot_mat = cv2.getRotationMatrix2D((img.shape[0]/2,img.shape[1]/2), rot_ang, scale);\n",
    "            img = cv2.warpAffine(img, rot_mat, (img.shape[0],img.shape[1]))\n",
    "        \n",
    "        # randomize thresholding\n",
    "        if self.training:\n",
    "            thresh_block_size = np.random.randint(5,9) // 2 * 2 + 1\n",
    "            thresh_param = np.random.randint(5,9)\n",
    "        else:\n",
    "            thresh_block_size = 7\n",
    "            thresh_param = 7\n",
    "        \n",
    "        img_he = self.clahe.apply(cv2.convertScaleAbs(img[:,:,0]))\n",
    "        img_mask = cv2.adaptiveThreshold(img_he, 1, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,\n",
    "                                         thresh_block_size, thresh_param)\n",
    "        img_ch = img_he * img_mask\n",
    "        \n",
    "        if n_channels == 1:\n",
    "            img = img_ch\n",
    "        elif n_channels == 3:\n",
    "            for i in xrange(img.shape[2]):\n",
    "                img[:,:,i] = img_ch\n",
    "        else:\n",
    "            print('\\n Wrong number of channels \\n')\n",
    "\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        \n",
    "#         image = cv2.imread(img_name)[:,:,::-1]\n",
    "        boneage = self.labels.iloc[idx]['boneage'].astype(np.float32)\n",
    "        gender = self.labels.iloc[idx]['male'].astype(np.uint16)\n",
    "        id = self.labels.iloc[idx]['id']\n",
    "        \n",
    "        label = np.hstack((boneage, gender, id))\n",
    "#         print(label)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        sample = {'image': img, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#         transforms.Scale(300),\n",
    "#         transforms.CenterCrop(384),\n",
    "        transforms.RandomSizedCrop(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "#         transforms.Scale(300),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(TRAIN_LABEL, dtype=np.uint16)\n",
    "bins = xrange(20)\n",
    "labels['bins'] = np.digitize(labels['boneage'], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/software/miniconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=4)\n",
    "splits = []\n",
    "for train, test in skf.split(np.zeros(len(labels)), labels['bins']):\n",
    "    fold_label = {\n",
    "        'train': labels.loc[train, ('id', 'boneage', 'male')],\n",
    "        'val': labels.loc[test, ('id', 'boneage', 'male')]\n",
    "    }\n",
    "    splits.append(fold_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_label = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_datasets = {x: BoneAgeDataset(TRAIN_DIR, fold_label[x], FILETYPE, img_size, data_transforms[x], x)\n",
    "                  for x in ['train', 'val']}\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=24, shuffle=True, num_workers=24, pin_memory=True)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([24, 1, 640, 640])\n",
      "0 0.257121661431\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample in enumerate(dataloders['val']):\n",
    "    print(i_batch, sample['image'].size())\n",
    "    print(i_batch, sample['image'].mean())\n",
    "#     for i in xrange(sample['image'].size()[0]):\n",
    "#         img = sample['image'][i,0,:,:].numpy()\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img, cmap=plt.cm.gray)\n",
    "    if i_batch == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (net): Sequential (\n",
      "    (0): Conv2d(1, 192, kernel_size=(5, 5), stride=(3, 3))\n",
      "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): Conv2d(192, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Conv2d(160, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU (inplace)\n",
      "    (9): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "    (10): Dropout (p = 0.5)\n",
      "    (11): Conv2d(96, 192, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (12): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (13): ReLU (inplace)\n",
      "    (14): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (15): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (16): ReLU (inplace)\n",
      "    (17): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (18): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (19): ReLU (inplace)\n",
      "    (20): AvgPool2d (size=3, stride=2, padding=0, ceil_mode=True, count_include_pad=True)\n",
      "    (21): Dropout (p = 0.5)\n",
      "    (22): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (23): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (24): ReLU (inplace)\n",
      "    (25): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (26): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (27): ReLU (inplace)\n",
      "    (28): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (29): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (30): ReLU (inplace)\n",
      "  )\n",
      "  (boneage_clf): Sequential (\n",
      "    (0): Dropout (p = 0.5)\n",
      "    (1): Linear (144 -> 96)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): Dropout (p = 0.5)\n",
      "    (4): Linear (96 -> 48)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Linear (48 -> 1)\n",
      "  )\n",
      "  (gender_clf): Sequential (\n",
      "    (0): Dropout (p = 0.5)\n",
      "    (1): Linear (144 -> 96)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): Dropout (p = 0.5)\n",
      "    (4): Linear (96 -> 48)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Linear (48 -> 1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_urls['inception_v3_google'] = model_urls['inception_v3_google'].replace('https://', 'http://')\n",
    "\n",
    "class AvgPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.view\n",
    "        return F.avg_pool2d(x, (x.size(2), x.size(3)))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape=(n_channels, img_size, img_size)):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "#         # inception_v3\n",
    "#         self.bn = nn.BatchNorm2d(input_shape[0])\n",
    "#         resnet = models.inception_v3(pretrained=True)\n",
    "        \n",
    "#         num_ftrs = resnet.fc.in_features\n",
    "#         resnet.fc = nn.Linear(num_ftrs, 1)\n",
    "        \n",
    "#         num_ftrs_aux = resnet.AuxLogits.fc.in_features\n",
    "#         resnet.AuxLogits.fc = nn.Linear(num_ftrs_aux, 1)\n",
    "        \n",
    "#         self.resnet = resnet\n",
    "        \n",
    "#         # resnet\n",
    "#         self.bn = nn.BatchNorm2d(input_shape[0])\n",
    "#         resnet = models.resnet50(pretrained=True)\n",
    "#         num_ftrs = resnet.fc.in_features\n",
    "#         resnet.fc = nn.Linear(num_ftrs, 1)\n",
    "#         self.resnet = resnet\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 192, 5, stride=3),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 160, 1, stride=1),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(160, 96, 1, stride=1),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(3, stride=2, ceil_mode=True),\n",
    "            nn.Dropout(),\n",
    "            \n",
    "            nn.Conv2d(96, 192, 5, stride=2),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 192, 1, stride=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 192, 1, stride=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.AvgPool2d(3, stride=2, ceil_mode=True),\n",
    "            nn.Dropout(),\n",
    "        \n",
    "            nn.Conv2d(192, 192, 3, stride=2),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 192, 1, stride=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 1, 1, stride=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(inplace=True)\n",
    "                                 \n",
    "#             nn.AvgPool2d(12, stride=12, ceil_mode=True)\n",
    "        )\n",
    "        self.boneage_clf = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(12*12, 96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(96, 48),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(48, 1)\n",
    "        )\n",
    "        self.gender_clf = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(12*12, 96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(96, 48),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(48, 1)\n",
    "        )\n",
    "        \n",
    "#         resnet.avgpool = nn.AdaptiveAvgPool2d(2)\n",
    "#         num_ftrs = net.fc.in_features\n",
    "#         net.fc = nn.Linear(num_ftrs, 1)\n",
    "#         self.net = net\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.net(self.bn(x))\n",
    "        x = self.net(x)\n",
    "#         print(x.size())\n",
    "        x = x.view(-1, 12*12)\n",
    "        g_x = self.gender_clf(x)\n",
    "        ba_x = self.boneage_clf(x)\n",
    "#         x = F.relu(self.lin128(F.dropout(x)))\n",
    "#         x = self.lin1(F.dropout(x))\n",
    "#         x = self.resnet(self.bn(x))\n",
    "#         return ba_x\n",
    "        return ba_x, g_x\n",
    "    \n",
    "model = Net([n_channels, img_size, img_size])\n",
    "    \n",
    "# print(summary([3, 640, 640], model))\n",
    "print(model)\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccc(x, y):\n",
    "#     print('X:', x)\n",
    "    mean_x = torch.mean(x)\n",
    "#     print('Mean x:', mean_x)\n",
    "    mean_y = torch.mean(y)\n",
    "#     print('Mean y:', mean_y)\n",
    "    xm = x.sub(mean_x)\n",
    "    ym = y.sub(mean_y)\n",
    "    xn = torch.norm(xm, 2)\n",
    "#     print('Xn:', xn)\n",
    "    yn = torch.norm(ym, 2)\n",
    "#     print('Yn:', yn)\n",
    "    xydot = ym.dot(xm.view(-1))\n",
    "#     print('XYdot:', xydot)\n",
    "\n",
    "    ccc_num = 2 * xydot / xm.size()[0]\n",
    "#     print('CCC num:', ccc_num)\n",
    "    ccc_den = xn + yn + torch.pow(mean_x.sub(mean_y), 2)\n",
    "#     print('CCC den:', ccc_den)\n",
    "\n",
    "    ccc = ccc_num / ccc_den\n",
    "    return ccc\n",
    "    \n",
    "\n",
    "def train(epoch, train_loader):\n",
    "    exp_lr_scheduler.step()\n",
    "    model.train()\n",
    "    train_boneage_loss = 0\n",
    "    train_gender_loss = 0\n",
    "    train_loss = 0\n",
    "    train_ccc = 0\n",
    "    num_samp = len(train_loader.dataset)\n",
    "    \n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         ba_output = model(data)\n",
    "        \n",
    "        # 2 heads MTL output\n",
    "        ba_output, g_output = model(data)\n",
    "#         print(output1)\n",
    "#         print(output2)\n",
    "        \n",
    "#         for i in xrange(output.size[0]):\n",
    "#             if output[i,1] > 0.5:\n",
    "#                 output[i,0] = (output[i,0] // 6) * 6\n",
    "#             else:\n",
    "#                 output[i,0] = (output[i,0] // 2) * 2\n",
    "\n",
    "#         boneage_out = torch.round(output[:,0].div(6)).mul(6)\n",
    "#         boneage_out = output[:,0]\n",
    "\n",
    "#         boneage_loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "#         train_boneage_loss += boneage_loss.data[0]\n",
    "        boneage_loss = F.smooth_l1_loss(ba_output.view(-1), target[:,0])\n",
    "        train_boneage_loss += boneage_loss.data[0]\n",
    "        \n",
    "        gender_loss = F.binary_cross_entropy_with_logits(g_output.view(-1), target[:,1])\n",
    "        train_gender_loss += gender_loss.data[0]\n",
    "        \n",
    "        loss = 0.75 * boneage_loss + 0.25 * gender_loss\n",
    "#         loss = boneage_loss\n",
    "#         loss = gender_loss\n",
    "#         loss = F.l1_loss(output1.view(-1), target[:,0]) + F.l1_loss(output2.view(-1), target[:,0])\n",
    "#         loss = 0.8 * F.l1_loss(output.view(-1), target[:,0]) + 0.2 * F.binary_cross_entropy(F.sigmoid(output.view(-1)), target[:,1])\n",
    "#         loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "        \n",
    "        train_loss += loss.data[0]\n",
    "#         c = ccc(boneage_out, target[:,0])\n",
    "        c = ccc(ba_output, target[:,0])\n",
    "        train_ccc += c.data.cpu().numpy()[0]\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % (1000 // len(target)) == 0:\n",
    "    print('Train ep: {} [{}/{} ({:.0f}%)]\\tBoneAge Loss: {:.4f}\\tGender Loss: {:.4f}\\t Loss: {:.4f}\\tCCC: {:.4f}'.format(\n",
    "        epoch, batch_idx * len(data), num_samp,\n",
    "        100. * batch_idx / num_samp, train_boneage_loss / num_samp,\n",
    "        train_gender_loss / num_samp, train_loss / num_samp,\n",
    "        train_ccc / num_samp))\n",
    "    \n",
    "#     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.4f}\\tCCC: {:.4f}'.format(\n",
    "#         epoch, batch_idx * len(data), num_samp,\n",
    "#         100. * batch_idx / num_samp, train_loss / num_samp, train_ccc / num_samp))\n",
    "\n",
    "def test(test_loader):\n",
    "    model.eval()\n",
    "    test_avg_gender = 0\n",
    "    test_boneage_loss = 0\n",
    "    test_boneage_l1_loss = 0\n",
    "    test_boneage_round_loss = 0\n",
    "    test_boneage_round_loss_2 = 0\n",
    "    test_boneage_round_loss_6 = 0\n",
    "    test_gender_loss = 0\n",
    "    test_loss = 0\n",
    "    test_ccc = 0\n",
    "    num_samp = len(test_loader.dataset)\n",
    "    for sample in test_loader:\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        print(sample['label'].int())\n",
    "\n",
    "#         test_avg_gender += sample['label'][:,1].sum()\n",
    "#         ba_output = model(data)\n",
    "        \n",
    "        # 2 heads MTL output\n",
    "        ba_output, g_output = model(data)\n",
    "#         print(ba_output)\n",
    "        \n",
    "#         print(output.size())\n",
    "#         boneage_out = torch.round(output[:,0].div(6)).mul(6)\n",
    "#         boneage_out = output[:,0]\n",
    "#         print(boneage_out)\n",
    "#         print(target[:,0])\n",
    "#         boneage_loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "\n",
    "        boneage_loss = F.smooth_l1_loss(ba_output.view(-1), target[:,0])\n",
    "        boneage_l1_loss = F.l1_loss(ba_output.view(-1), target[:,0])\n",
    "# #         print(boneage_loss)\n",
    "        boneage_round_loss = F.l1_loss(torch.round(ba_output.view(-1)), target[:,0])\n",
    "# #         print(boneage_round_loss)\n",
    "        boneage_round_loss_2 = F.l1_loss(torch.round(ba_output.view(-1).div(2)).mul(2), target[:,0])\n",
    "# #         print(boneage_round_loss_2)\n",
    "        boneage_round_loss_6 = F.l1_loss(torch.round(ba_output.view(-1).div(6)).mul(6), target[:,0])\n",
    "# #         print(boneage_round_loss_6)\n",
    "        \n",
    "        test_boneage_loss += boneage_loss.data[0]\n",
    "        test_boneage_l1_loss += boneage_l1_loss.data[0]\n",
    "        test_boneage_round_loss += boneage_round_loss.data[0]\n",
    "        test_boneage_round_loss_2 += boneage_round_loss_2.data[0]\n",
    "        test_boneage_round_loss_6 += boneage_round_loss_6.data[0]\n",
    "    \n",
    "#         print(test_boneage_loss)\n",
    "        gender_loss = F.binary_cross_entropy_with_logits(g_output.view(-1), target[:,1])\n",
    "        test_gender_loss += gender_loss.data[0]\n",
    "\n",
    "        loss = 0.75 * boneage_loss + 0.25 * gender_loss\n",
    "#         loss = boneage_loss\n",
    "#         loss = 0.8 * F.l1_loss(output.view(-1), target[:,0]) + 0.2 * F.binary_cross_entropy(F.sigmoid(output.view(-1)), target[:,1])\n",
    "#         loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "\n",
    "        test_loss += loss.data[0]\n",
    "#         c = ccc(boneage_out, target[:,0])\n",
    "        c = ccc(ba_output, target[:,0])\n",
    "        test_ccc += c.data.cpu().numpy()[0]\n",
    "\n",
    "    print('\\nTest set: BoneAge loss: {:.4f}, Gender loss: {:.4f}, loss: {:.4f}, CCC: {:.4f}'.format(\n",
    "        test_boneage_loss / num_samp, test_gender_loss / num_samp,\n",
    "        test_loss / num_samp, test_ccc / num_samp))\n",
    "    print('\\nTest set: L1 loss: {:.4f},Round loss: {:.4f}, Round2 loss: {:.4f}, Round6: {:.4f}, Gender: {:.4f}\\n'.format(\n",
    "        test_boneage_l1_loss / num_samp, test_boneage_round_loss / num_samp, test_boneage_round_loss_2 / num_samp,\n",
    "        test_boneage_round_loss_6 / num_samp, test_avg_gender / num_samp))\n",
    "    \n",
    "#     print('\\nTest set: Avg loss: {:.4f} CCC: {:.4f}\\n'.format(\n",
    "#         test_loss / num_samp, test_ccc / num_samp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '../models/9-27-1540-resnet50-1fold-5.7889-2.56.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 60 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
