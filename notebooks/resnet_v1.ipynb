{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import sparseconvnet.legacy as scn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline\n",
    "%env TMP=\"/tmp\"\n",
    "%env JOBLIB_TEMP_FOLDER=\"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary(input_size, model):\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            m_key = '%s-%i' % (class_name, module_idx+1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key]['input_shape'] = list(input[0].size())\n",
    "            summary[m_key]['input_shape'][0] = -1\n",
    "            summary[m_key]['output_shape'] = list(output.size())\n",
    "            summary[m_key]['output_shape'][0] = -1\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, 'weight'):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                if module.weight.requires_grad:\n",
    "                    summary[m_key]['trainable'] = True\n",
    "                else:\n",
    "                    summary[m_key]['trainable'] = False\n",
    "            if hasattr(module, 'bias'):\n",
    "                params +=  torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key]['nb_params'] = params\n",
    "\n",
    "        if not isinstance(module, nn.Sequential) and \\\n",
    "           not isinstance(module, nn.ModuleList) and \\\n",
    "           not (module == model):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    # check if there are multiple inputs to the network\n",
    "    if isinstance(input_size[0], (list, tuple)):\n",
    "        x = [Variable(torch.rand(1,*in_size)) for in_size in input_size]\n",
    "    else:\n",
    "        x = Variable(torch.rand(1,*input_size))\n",
    "\n",
    "    # create properties\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "    # make a forward pass\n",
    "    model(x)\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../data/boneage-training-dataset/'\n",
    "TRAIN_LABEL = '../data/train.csv'\n",
    "FILETYPE = '.png'\n",
    "img_size = 640\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BoneAgeDataset(Dataset):\n",
    "    \"\"\"Bone Age dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, labels, filetype, img_size, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.filetype = filetype\n",
    "        self.img_size = img_size\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, str(self.labels.iloc[idx]['id']) + self.filetype)\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        img = img.point(lambda x: x if x<200 else 0)\n",
    "#         print('PIL size:', img.size)\n",
    "        img = np.asarray(img)\n",
    "#         print('Np size: ',img.shape)\n",
    "        if img.shape[1] > img.shape[0]:\n",
    "#             print(img.shape)\n",
    "            img = np.swapaxes(img,0,1)\n",
    "        img = cv2.resize(img, (740,950))\n",
    "        img = img[210:,:]\n",
    "#         print(img.shape)\n",
    "        rot_ang = range(0,360,30)\n",
    "        rot_ang = rot_ang[np.random.randint(0,len(rot_ang))]\n",
    "#         print(rot_ang)\n",
    "        scale = np.random.uniform(0.8,1.2)\n",
    "#         print(scale)\n",
    "        rot_mat = cv2.getRotationMatrix2D((img.shape[0]/2,img.shape[1]/2), rot_ang, scale);\n",
    "        img = cv2.warpAffine(img, rot_mat, (img.shape[0],img.shape[1]))\n",
    "        img_he = self.clahe.apply(cv2.convertScaleAbs(img[:,:,0]))\n",
    "        img_mask = cv2.adaptiveThreshold(img_he, 1, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,\n",
    "                                         np.random.randint(5,9) // 2 * 2 + 1, np.random.randint(5,9))\n",
    "        img_ch = img_he * img_mask\n",
    "        \n",
    "        img = img_ch\n",
    "#         for i in xrange(img.shape[2]):\n",
    "#             img[:,:,i] = img_ch\n",
    "\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        \n",
    "#         image = cv2.imread(img_name)[:,:,::-1]\n",
    "        boneage = self.labels.iloc[idx]['boneage'].astype(np.float32)\n",
    "        gender = self.labels.iloc[idx]['male'].astype(np.uint8)\n",
    "        \n",
    "        label = np.hstack((boneage, gender))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        sample = {'image': img, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#         transforms.Scale(300),\n",
    "#         transforms.CenterCrop(384),\n",
    "        transforms.RandomSizedCrop(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "#         transforms.Scale(300),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(TRAIN_LABEL)\n",
    "bins = xrange(20)\n",
    "labels['bins'] = np.digitize(labels['boneage'], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=4)\n",
    "splits = []\n",
    "for train, test in skf.split(np.zeros(len(labels)), labels['bins']):\n",
    "    fold_label = {\n",
    "        'train': labels.loc[train, ('id', 'boneage', 'male')],\n",
    "        'val': labels.loc[test, ('id', 'boneage', 'male')]\n",
    "    }\n",
    "    splits.append(fold_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_label = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_datasets = {x: BoneAgeDataset(TRAIN_DIR, fold_label[x], FILETYPE, img_size, data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=24, pin_memory=True)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample in enumerate(dataloders['val']):\n",
    "    print(i_batch, sample['image'].size())\n",
    "    print(i_batch, sample['image'].mean())\n",
    "#     for i in xrange(sample['image'].size()[0]):\n",
    "#         img = sample['image'][i,0,:,:].numpy()\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img, cmap=plt.cm.gray)\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape=(1, img_size, img_size)):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "#         self.bn = nn.BatchNorm2d(input_shape[0])\n",
    "#         net = models.vgg16(pretrained=False)\n",
    "        self.net = nn.DataParallel(nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 192, 5, stride=3),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(192, 160, 1, stride=1),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(160, 96, 1, stride=1),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(3, stride=2, ceil_mode=True),\n",
    "            nn.Dropout(),\n",
    "            \n",
    "            nn.Conv2d(96, 192, 5, stride=2),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(192, 192, 1, stride=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(192, 192, 1, stride=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.AvgPool2d(3, stride=2, ceil_mode=True),\n",
    "            nn.Dropout(),\n",
    "            \n",
    "            nn.Conv2d(192, 192, 3), stride=2),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(192, 192, 1, stride=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(192, 1, 1, stride=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.AvgPool2d(12, stride=12, ceil_mode=True),\n",
    "        ))\n",
    "#         resnet.avgpool = nn.AdaptiveAvgPool2d(2)\n",
    "#         num_ftrs = net.fc.in_features\n",
    "#         net.fc = nn.Linear(num_ftrs, 1)\n",
    "#         self.net = net\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.net(self.bn(x))\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "    \n",
    "model = Net([1, img_size, img_size])\n",
    "    \n",
    "# print(summary([3, 640, 640], model))\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ccc(x, y):\n",
    "#     print('X:', x)\n",
    "    mean_x = torch.mean(x)\n",
    "#     print('Mean x:', mean_x)\n",
    "    mean_y = torch.mean(y)\n",
    "#     print('Mean y:', mean_y)\n",
    "    xm = x.sub(mean_x)\n",
    "    ym = y.sub(mean_y)\n",
    "    xn = torch.norm(xm, 2)\n",
    "#     print('Xn:', xn)\n",
    "    yn = torch.norm(ym, 2)\n",
    "#     print('Yn:', yn)\n",
    "    xydot = ym.dot(xm.view(-1))\n",
    "#     print('XYdot:', xydot)\n",
    "\n",
    "    ccc_num = 2 * xydot / xm.size()[0]\n",
    "#     print('CCC num:', ccc_num)\n",
    "    ccc_den = xn + yn + torch.pow(mean_x.sub(mean_y), 2)\n",
    "#     print('CCC den:', ccc_den)\n",
    "\n",
    "    ccc = ccc_num / ccc_den\n",
    "    return ccc\n",
    "    \n",
    "\n",
    "def train(epoch, train_loader):\n",
    "    exp_lr_scheduler.step()\n",
    "    model.train()\n",
    "    train_boneage_loss = 0\n",
    "    train_gender_loss = 0\n",
    "    train_loss = 0\n",
    "    train_ccc = 0\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         print(output.size())\n",
    "        \n",
    "#         for i in xrange(output.size[0]):\n",
    "#             if output[i,1] > 0.5:\n",
    "#                 output[i,0] = (output[i,0] // 6) * 6\n",
    "#             else:\n",
    "#                 output[i,0] = (output[i,0] // 2) * 2\n",
    "\n",
    "#         boneage_out = torch.round(output[:,0].div(6)).mul(6)\n",
    "#         boneage_out = output[:,0]\n",
    "#         boneage_loss = F.l1_loss(boneage_out, target[:,0])\n",
    "#         train_boneage_loss += boneage_loss.data[0]\n",
    "#         gender_loss = F.binary_cross_entropy(F.sigmoid(output[:,1]), target[:,1])\n",
    "#         train_gender_loss += gender_loss.data[0]\n",
    "#         loss = 0.95 * boneage_loss + 0.05 * gender_loss\n",
    "#         loss = 0.8 * F.l1_loss(output.view(-1), target[:,0]) + 0.2 * F.binary_cross_entropy(F.sigmoid(output.view(-1)), target[:,1])\n",
    "        loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "        train_loss += loss.data[0]\n",
    "#         c = ccc(boneage_out, target[:,0])\n",
    "        c = ccc(output, target[:,0])\n",
    "        train_ccc += c.data.cpu().numpy()[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % (1000 // len(target)) == 0:\n",
    "#     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tBoneAge Loss: {:.4f}\\tGender Loss: {:.4f}\\t Loss: {:.4f}\\tCCC: {:.4f}'.format(\n",
    "#         epoch, batch_idx * len(data), len(train_loader),\n",
    "#         100. * batch_idx / len(train_loader), train_boneage_loss / len(train_loader),\n",
    "#         train_gender_loss / len(train_loader), train_loss / len(train_loader),\n",
    "#         train_ccc / len(train_loader)))\n",
    "    \n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.4f}\\tCCC: {:.4f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader),\n",
    "        100. * batch_idx / len(train_loader), train_loss / len(train_loader),\n",
    "        train_ccc / len(train_loader)))\n",
    "\n",
    "def test(test_loader):\n",
    "    model.eval()\n",
    "    test_boneage_loss = 0\n",
    "    test_gender_loss = 0\n",
    "    test_loss = 0\n",
    "    test_ccc = 0\n",
    "    for sample in test_loader:\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "#         print(output.size())\n",
    "#         boneage_out = torch.round(output[:,0].div(6)).mul(6)\n",
    "#         boneage_out = output[:,0]\n",
    "#         print(boneage_out)\n",
    "#         print(target[:,0])\n",
    "#         boneage_loss = F.l1_loss(boneage_out, target[:,0])\n",
    "#         print(boneage_loss)\n",
    "#         test_boneage_loss += boneage_loss.data[0]\n",
    "#         print(test_boneage_loss)\n",
    "#         gender_loss = F.binary_cross_entropy(F.sigmoid(output[:,1]), target[:,1])\n",
    "#         test_gender_loss += gender_loss.data[0]\n",
    "#         loss = 0.95 * boneage_loss + 0.05 * gender_loss\n",
    "#         loss = 0.8 * F.l1_loss(output.view(-1), target[:,0]) + 0.2 * F.binary_cross_entropy(F.sigmoid(output.view(-1)), target[:,1])\n",
    "        loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "        test_loss += loss.data[0]\n",
    "#         c = ccc(boneage_out, target[:,0])\n",
    "        c = ccc(output, target[:,0])\n",
    "        test_ccc += c.data.cpu().numpy()[0]\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "#     print('\\nTest set: Avg BoneAge loss: {:.4f}, Avg Gender loss: {:.4f}, Avg loss: {:.4f} CCC: {:.4f}\\n'.format(\n",
    "#         test_boneage_loss / len(test_loader), test_gender_loss / len(test_loader),\n",
    "#         test_loss / len(test_loader), test_ccc / len(test_loader)))\n",
    "    \n",
    "    print('\\nTest set: Avg loss: {:.4f} CCC: {:.4f}\\n'.format(\n",
    "        test_loss / len(test_loader), test_ccc / len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '../models/9-27-1540-resnet50-1fold-5.7889-2.56.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 100 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 100 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 100 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 30 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
