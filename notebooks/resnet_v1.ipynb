{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TMP=\"/tmp\"\n",
      "env: JOBLIB_TEMP_FOLDER=\"/tmp\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models.inception import model_urls\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import sparseconvnet.legacy as scn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline\n",
    "%env TMP=\"/tmp\"\n",
    "%env JOBLIB_TEMP_FOLDER=\"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary(input_size, model):\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            m_key = '%s-%i' % (class_name, module_idx+1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key]['input_shape'] = list(input[0].size())\n",
    "            summary[m_key]['input_shape'][0] = -1\n",
    "            summary[m_key]['output_shape'] = list(output.size())\n",
    "            summary[m_key]['output_shape'][0] = -1\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, 'weight'):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                if module.weight.requires_grad:\n",
    "                    summary[m_key]['trainable'] = True\n",
    "                else:\n",
    "                    summary[m_key]['trainable'] = False\n",
    "            if hasattr(module, 'bias'):\n",
    "                params +=  torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key]['nb_params'] = params\n",
    "\n",
    "        if not isinstance(module, nn.Sequential) and \\\n",
    "           not isinstance(module, nn.ModuleList) and \\\n",
    "           not (module == model):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    # check if there are multiple inputs to the network\n",
    "    if isinstance(input_size[0], (list, tuple)):\n",
    "        x = [Variable(torch.rand(1,*in_size)) for in_size in input_size]\n",
    "    else:\n",
    "        x = Variable(torch.rand(1,*input_size))\n",
    "\n",
    "    # create properties\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "    # make a forward pass\n",
    "    model(x)\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../data/boneage-training-dataset/'\n",
    "TEST_DIR = '../data/boneage-validation-dataset/'\n",
    "TRAIN_LABEL = '../data/train.csv'\n",
    "TEST_LABEL = '../data/dataset_data_file-validation-gender-fa677c87-bd0d-44a1-92f3-f5966389798b.csv'\n",
    "FILETYPE = '.png'\n",
    "img_scale = 900\n",
    "img_size = 840\n",
    "n_channels = 1\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoneAgeDataset(Dataset):\n",
    "    \"\"\"Bone Age dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, labels, filetype, img_size, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.filetype = filetype\n",
    "        self.img_size = img_size\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        self.training = True if mode == 'train' else False\n",
    "        self.predicting = True if mode == 'pred' else False\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         print(idx)\n",
    "#         sample = 1.0\n",
    "        img_name = os.path.join(self.root_dir, str(self.labels.iloc[idx]['id']) + self.filetype)\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "#         print(img_name, img.size)\n",
    "        \n",
    "        # randomize thresholding\n",
    "        if self.training:\n",
    "            img = img.point(lambda x: x if x < np.random.randint(200,220) else 0)\n",
    "        else:\n",
    "            img = img.point(lambda x: x if x < 220 else 0)\n",
    "            \n",
    "        # resizing\n",
    "#         print('PIL size:', img.size)\n",
    "        img = np.asarray(img)\n",
    "#         print('Np size: ',img.shape)\n",
    "        if img.shape[1] > img.shape[0]:\n",
    "#             print(img.shape)\n",
    "            img = np.swapaxes(img,0,1)\n",
    "    \n",
    "        img = cv2.resize(img, (img_scale,img_scale))\n",
    "\n",
    "#         img = cv2.resize(img, (img_scale,img_scale+210))\n",
    "#         img = img[210:,:]\n",
    "#         print(img.shape)\n",
    "\n",
    "        # rotation\n",
    "        if self.training:\n",
    "            rot_ang = range(0,360,30)\n",
    "            rot_ang = rot_ang[np.random.randint(0,len(rot_ang))]\n",
    "    #         print(rot_ang)\n",
    "            scale = np.random.uniform(0.8,1.2)\n",
    "    #         print(scale)\n",
    "            rot_mat = cv2.getRotationMatrix2D((img.shape[0]/2,img.shape[1]/2), rot_ang, scale);\n",
    "            img = cv2.warpAffine(img, rot_mat, (img.shape[0],img.shape[1]))\n",
    "        \n",
    "        # randomize thresholding\n",
    "        if self.training:\n",
    "            thresh_block_size = np.random.randint(5,9) // 2 * 2 + 1\n",
    "            thresh_param = np.random.randint(5,9)\n",
    "        else:\n",
    "            thresh_block_size = 7\n",
    "            thresh_param = 7\n",
    "        \n",
    "        img_he = self.clahe.apply(cv2.convertScaleAbs(img[:,:,0]))\n",
    "        img_mask = cv2.adaptiveThreshold(img_he, 1, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,\n",
    "                                         thresh_block_size, thresh_param)\n",
    "        img_ch = img_he * img_mask\n",
    "        \n",
    "        if n_channels == 1:\n",
    "            img = img_ch\n",
    "        elif n_channels == 3:\n",
    "            for i in xrange(img.shape[2]):\n",
    "                img[:,:,i] = img_ch\n",
    "        else:\n",
    "            print('\\n Wrong number of channels \\n')\n",
    "\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "#         print('Img:', img.size)\n",
    "        \n",
    "#         image = cv2.imread(img_name)[:,:,::-1]\n",
    "        gender = self.labels.iloc[idx]['male'].astype(np.int32)\n",
    "        pat_id = self.labels.iloc[idx]['id'].astype(np.int32)\n",
    "        \n",
    "        if not self.predicting:\n",
    "            boneage = self.labels.iloc[idx]['boneage'].astype(np.float32)\n",
    "            label = np.hstack((boneage, gender, pat_id))\n",
    "        else:\n",
    "            label = np.hstack((gender, pat_id))\n",
    "#         print(label)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        sample = {'image': img, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#         transforms.Scale(300),\n",
    "#         transforms.CenterCrop(384),\n",
    "        transforms.RandomSizedCrop(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "#         transforms.Scale(300),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'pred': transforms.Compose([\n",
    "#         transforms.Scale(300),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(TRAIN_LABEL, dtype=np.uint16)\n",
    "bins = xrange(20)\n",
    "labels['bins'] = np.digitize(labels['boneage'], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/software/miniconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=7.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=7)\n",
    "splits = []\n",
    "for train, test in skf.split(np.zeros(len(labels)), labels['bins']):\n",
    "    fold_label = {\n",
    "        'train': labels.loc[train, ('id', 'boneage', 'male')],\n",
    "        'val': labels.loc[test, ('id', 'boneage', 'male')]\n",
    "    }\n",
    "    splits.append(fold_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_label = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_datasets = {x: BoneAgeDataset(TRAIN_DIR, fold_label[x], FILETYPE, img_size, data_transforms[x], x)\n",
    "                  for x in ['train', 'val']}\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=24, shuffle=True, num_workers=24, pin_memory=True)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([24, 1, 840, 840])\n",
      "0 0.269442812354\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample in enumerate(dataloders['val']):\n",
    "    print(i_batch, sample['image'].size())\n",
    "    print(i_batch, sample['image'].mean())\n",
    "#     for i in xrange(sample['image'].size()[0]):\n",
    "#         img = sample['image'][i,0,:,:].numpy()\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img, cmap=plt.cm.gray)\n",
    "    if i_batch == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (net): Sequential (\n",
      "    (0): Conv2d(1, 192, kernel_size=(5, 5), stride=(3, 3))\n",
      "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): Conv2d(192, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Conv2d(160, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU (inplace)\n",
      "    (9): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "    (10): Dropout (p = 0.5)\n",
      "    (11): Conv2d(96, 192, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (12): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (13): ReLU (inplace)\n",
      "    (14): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (15): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (16): ReLU (inplace)\n",
      "    (17): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (18): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (19): ReLU (inplace)\n",
      "    (20): AvgPool2d (size=3, stride=2, padding=0, ceil_mode=True, count_include_pad=True)\n",
      "    (21): Dropout (p = 0.5)\n",
      "    (22): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (23): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (24): ReLU (inplace)\n",
      "    (25): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (26): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (27): ReLU (inplace)\n",
      "    (28): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (29): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (30): ReLU (inplace)\n",
      "  )\n",
      "  (boneage_clf): Sequential (\n",
      "    (0): Dropout (p = 0.5)\n",
      "    (1): Linear (144 -> 72)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): Dropout (p = 0.5)\n",
      "    (4): Linear (72 -> 32)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Linear (32 -> 1)\n",
      "  )\n",
      "  (gender_clf): Sequential (\n",
      "    (0): Dropout (p = 0.5)\n",
      "    (1): Linear (144 -> 72)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): Dropout (p = 0.5)\n",
      "    (4): Linear (72 -> 32)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Linear (32 -> 1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_urls['inception_v3_google'] = model_urls['inception_v3_google'].replace('https://', 'http://')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape=(n_channels, img_size, img_size)):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "#         # inception_v3\n",
    "#         self.bn = nn.BatchNorm2d(input_shape[0])\n",
    "#         resnet = models.inception_v3(pretrained=True)\n",
    "        \n",
    "#         num_ftrs = resnet.fc.in_features\n",
    "#         resnet.fc = nn.Linear(num_ftrs, 1)\n",
    "        \n",
    "#         num_ftrs_aux = resnet.AuxLogits.fc.in_features\n",
    "#         resnet.AuxLogits.fc = nn.Linear(num_ftrs_aux, 1)\n",
    "        \n",
    "#         self.resnet = resnet\n",
    "        \n",
    "#         # resnet\n",
    "#         self.bn = nn.BatchNorm2d(input_shape[0])\n",
    "#         resnet = models.resnet50(pretrained=True)\n",
    "#         num_ftrs = resnet.fc.in_features\n",
    "#         resnet.fc = nn.Linear(num_ftrs, 1)\n",
    "#         self.resnet = resnet\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 192, 5, stride=3),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 160, 1, stride=1),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(160, 96, 1, stride=1),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(3, stride=2, ceil_mode=True),\n",
    "            nn.Dropout(),\n",
    "            \n",
    "            nn.Conv2d(96, 192, 5, stride=2),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 192, 1, stride=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 192, 1, stride=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.AvgPool2d(3, stride=2, ceil_mode=True),\n",
    "            nn.Dropout(),\n",
    "        \n",
    "            nn.Conv2d(192, 192, 3, stride=2),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 192, 1, stride=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 1, 1, stride=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(inplace=True)\n",
    "                                 \n",
    "#             nn.AvgPool2d(12, stride=12, ceil_mode=True)\n",
    "        )\n",
    "        self.boneage_clf = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(12*12, 72),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(72, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        self.gender_clf = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(12*12, 72),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(72, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "#         resnet.avgpool = nn.AdaptiveAvgPool2d(2)\n",
    "#         num_ftrs = net.fc.in_features\n",
    "#         net.fc = nn.Linear(num_ftrs, 1)\n",
    "#         self.net = net\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.net(self.bn(x))\n",
    "        x = self.net(x)\n",
    "#         print(x.size())\n",
    "        x = x.view(-1, 12*12)\n",
    "        g_x = self.gender_clf(x)\n",
    "        ba_x = self.boneage_clf(x)\n",
    "#         x = F.relu(self.lin128(F.dropout(x)))\n",
    "#         x = self.lin1(F.dropout(x))\n",
    "#         x = self.resnet(self.bn(x))\n",
    "#         return ba_x\n",
    "        return ba_x, g_x\n",
    "    \n",
    "model = Net([n_channels, img_size, img_size])\n",
    "    \n",
    "# print(summary([3, 640, 640], model))\n",
    "print(model)\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ccc(x, y):\n",
    "#     print('X:', x)\n",
    "    mean_x = torch.mean(x)\n",
    "#     print('Mean x:', mean_x)\n",
    "    mean_y = torch.mean(y)\n",
    "#     print('Mean y:', mean_y)\n",
    "    xm = x.sub(mean_x)\n",
    "    ym = y.sub(mean_y)\n",
    "    xn = torch.norm(xm, 2)\n",
    "#     print('Xn:', xn)\n",
    "    yn = torch.norm(ym, 2)\n",
    "#     print('Yn:', yn)\n",
    "    xydot = ym.dot(xm.view(-1))\n",
    "#     print('XYdot:', xydot)\n",
    "\n",
    "    ccc_num = 2 * xydot / xm.size()[0]\n",
    "#     print('CCC num:', ccc_num)\n",
    "    ccc_den = xn + yn + torch.pow(mean_x.sub(mean_y), 2)\n",
    "#     print('CCC den:', ccc_den)\n",
    "\n",
    "    ccc = ccc_num / ccc_den\n",
    "    return ccc\n",
    "    \n",
    "\n",
    "def train(epoch, train_loader):\n",
    "    exp_lr_scheduler.step()\n",
    "    model.train()\n",
    "    train_boneage_loss = 0\n",
    "    train_gender_loss = 0\n",
    "    train_loss = 0\n",
    "    train_ccc = 0\n",
    "    num_samp = len(train_loader.dataset)\n",
    "    \n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         ba_output = model(data)\n",
    "        \n",
    "        # 2 heads MTL output\n",
    "        ba_output, g_output = model(data)\n",
    "#         print(output1)\n",
    "#         print(output2)\n",
    "        \n",
    "#         for i in xrange(output.size[0]):\n",
    "#             if output[i,1] > 0.5:\n",
    "#                 output[i,0] = (output[i,0] // 6) * 6\n",
    "#             else:\n",
    "#                 output[i,0] = (output[i,0] // 2) * 2\n",
    "\n",
    "#         boneage_out = torch.round(output[:,0].div(6)).mul(6)\n",
    "#         boneage_out = output[:,0]\n",
    "\n",
    "#         boneage_loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "#         train_boneage_loss += boneage_loss.data[0]\n",
    "        boneage_loss = F.smooth_l1_loss(ba_output.view(-1), target[:,0])\n",
    "        train_boneage_loss += boneage_loss.data[0]\n",
    "        \n",
    "        gender_loss = F.binary_cross_entropy_with_logits(g_output.view(-1), target[:,1])\n",
    "        train_gender_loss += gender_loss.data[0]\n",
    "        \n",
    "        loss = 0.75 * boneage_loss + 0.25 * gender_loss\n",
    "#         loss = boneage_loss\n",
    "#         loss = gender_loss\n",
    "#         loss = F.l1_loss(output1.view(-1), target[:,0]) + F.l1_loss(output2.view(-1), target[:,0])\n",
    "#         loss = 0.8 * F.l1_loss(output.view(-1), target[:,0]) + 0.2 * F.binary_cross_entropy(F.sigmoid(output.view(-1)), target[:,1])\n",
    "#         loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "        \n",
    "        train_loss += loss.data[0]\n",
    "#         c = ccc(boneage_out, target[:,0])\n",
    "        c = ccc(ba_output, target[:,0])\n",
    "        train_ccc += c.data.cpu().numpy()[0]\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % (1000 // len(target)) == 0:\n",
    "    print('Train ep: {} [{}/{} ({:.0f}%)]\\tBoneAge Loss: {:.4f}\\tGender Loss: {:.4f}\\t Loss: {:.4f}\\tCCC: {:.4f}'.format(\n",
    "        epoch, batch_idx * len(data), num_samp,\n",
    "        100. * batch_idx / num_samp, train_boneage_loss / num_samp,\n",
    "        train_gender_loss / num_samp, train_loss / num_samp,\n",
    "        train_ccc / num_samp))\n",
    "    \n",
    "#     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.4f}\\tCCC: {:.4f}'.format(\n",
    "#         epoch, batch_idx * len(data), num_samp,\n",
    "#         100. * batch_idx / num_samp, train_loss / num_samp, train_ccc / num_samp))\n",
    "\n",
    "def test(test_loader):\n",
    "    model.eval()\n",
    "    test_avg_gender = 0\n",
    "    test_boneage_loss = 0\n",
    "    test_boneage_l1_loss = 0\n",
    "    test_boneage_round_loss = 0\n",
    "    test_boneage_round_loss_2 = 0\n",
    "    test_boneage_round_loss_6 = 0\n",
    "    test_gender_loss = 0\n",
    "    test_loss = 0\n",
    "    test_ccc = 0\n",
    "    num_samp = len(test_loader.dataset)\n",
    "    for sample in test_loader:\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "\n",
    "#         test_avg_gender += sample['label'][:,1].sum()\n",
    "#         ba_output = model(data)\n",
    "        \n",
    "        # 2 heads MTL output\n",
    "        ba_output, g_output = model(data)\n",
    "#         print(ba_output)\n",
    "        \n",
    "#         print(output.size())\n",
    "#         boneage_out = torch.round(output[:,0].div(6)).mul(6)\n",
    "#         boneage_out = output[:,0]\n",
    "#         print(boneage_out)\n",
    "#         print(target[:,0])\n",
    "#         boneage_loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "\n",
    "        boneage_loss = F.smooth_l1_loss(ba_output.view(-1), target[:,0])\n",
    "        boneage_l1_loss = F.l1_loss(ba_output.view(-1), target[:,0])\n",
    "# #         print(boneage_loss)\n",
    "        boneage_round_loss = F.l1_loss(torch.round(ba_output.view(-1)), target[:,0])\n",
    "# #         print(boneage_round_loss)\n",
    "        boneage_round_loss_2 = F.l1_loss(torch.round(ba_output.view(-1).div(2)).mul(2), target[:,0])\n",
    "# #         print(boneage_round_loss_2)\n",
    "        boneage_round_loss_6 = F.l1_loss(torch.round(ba_output.view(-1).div(6)).mul(6), target[:,0])\n",
    "# #         print(boneage_round_loss_6)\n",
    "        \n",
    "        test_boneage_loss += boneage_loss.data[0]\n",
    "        test_boneage_l1_loss += boneage_l1_loss.data[0]\n",
    "        test_boneage_round_loss += boneage_round_loss.data[0]\n",
    "        test_boneage_round_loss_2 += boneage_round_loss_2.data[0]\n",
    "        test_boneage_round_loss_6 += boneage_round_loss_6.data[0]\n",
    "    \n",
    "#         print(test_boneage_loss)\n",
    "        gender_loss = F.binary_cross_entropy_with_logits(g_output.view(-1), target[:,1])\n",
    "        test_gender_loss += gender_loss.data[0]\n",
    "\n",
    "        loss = 0.75 * boneage_loss + 0.25 * gender_loss\n",
    "#         loss = boneage_loss\n",
    "#         loss = 0.8 * F.l1_loss(output.view(-1), target[:,0]) + 0.2 * F.binary_cross_entropy(F.sigmoid(output.view(-1)), target[:,1])\n",
    "#         loss = F.l1_loss(output.view(-1), target[:,0])\n",
    "\n",
    "        test_loss += loss.data[0]\n",
    "#         c = ccc(boneage_out, target[:,0])\n",
    "        c = ccc(ba_output, target[:,0])\n",
    "        test_ccc += c.data.cpu().numpy()[0]\n",
    "\n",
    "    print('\\nTest set: BoneAge loss: {:.4f}, Gender loss: {:.4f}, loss: {:.4f}, CCC: {:.4f}'.format(\n",
    "        test_boneage_loss / num_samp, test_gender_loss / num_samp,\n",
    "        test_loss / num_samp, test_ccc / num_samp))\n",
    "    print('\\nTest set: L1 loss: {:.4f},Round loss: {:.4f}, Round2 loss: {:.4f}, Round6: {:.4f}, Gender: {:.4f}\\n'.format(\n",
    "        test_boneage_l1_loss / num_samp, test_boneage_round_loss / num_samp, test_boneage_round_loss_2 / num_samp,\n",
    "        test_boneage_round_loss_6 / num_samp, test_avg_gender / num_samp))\n",
    "    \n",
    "#     print('\\nTest set: Avg loss: {:.4f} CCC: {:.4f}\\n'.format(\n",
    "#         test_loss / num_samp, test_ccc / num_samp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: size '[-1 x 144]' is invalid for input of with 6144 elements at /opt/conda/conda-bld/pytorch_1502006348621/work/torch/lib/TH/THStorage.c:37",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-9134c790e817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-a071ad8b532b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, train_loader)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# 2 heads MTL output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mba_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m#         print(output1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#         print(output2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/software/miniconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-9824832c03b7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m#         print(x.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgender_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mba_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboneage_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/software/miniconda2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mview\u001b[0;34m(self, *sizes)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mView\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/software/miniconda2/lib/python2.7/site-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, sizes)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_shared_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: size '[-1 x 144]' is invalid for input of with 6144 elements at /opt/conda/conda-bld/pytorch_1502006348621/work/torch/lib/TH/THStorage.c:37"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 60 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ep: 61 [3835/9453 (3%)]\tBoneAge Loss: 0.9088\tGender Loss: 0.0216\t Loss: 0.6870\tCCC: 0.0578\n",
      "\n",
      "Test set: BoneAge loss: 1.4785, Gender loss: 0.0216, loss: 1.1143, CCC: 0.0071\n",
      "\n",
      "Test set: L1 loss: 1.4941,Round loss: 1.4937, Round2 loss: 1.4937, Round6: 1.4855, Gender: 0.0000\n",
      "\n",
      "Train ep: 62 [3835/9453 (3%)]\tBoneAge Loss: 0.8896\tGender Loss: 0.0216\t Loss: 0.6726\tCCC: 0.0632\n",
      "\n",
      "Test set: BoneAge loss: 1.5119, Gender loss: 0.0216, loss: 1.1394, CCC: 0.0089\n",
      "\n",
      "Test set: L1 loss: 1.5276,Round loss: 1.5273, Round2 loss: 1.5289, Round6: 1.5372, Gender: 0.0000\n",
      "\n",
      "Train ep: 63 [3835/9453 (3%)]\tBoneAge Loss: 0.8754\tGender Loss: 0.0216\t Loss: 0.6619\tCCC: 0.0664\n",
      "\n",
      "Test set: BoneAge loss: 1.3223, Gender loss: 0.0216, loss: 0.9972, CCC: 0.0113\n",
      "\n",
      "Test set: L1 loss: 1.3380,Round loss: 1.3382, Round2 loss: 1.3377, Round6: 1.3378, Gender: 0.0000\n",
      "\n",
      "Train ep: 64 [3835/9453 (3%)]\tBoneAge Loss: 0.8781\tGender Loss: 0.0216\t Loss: 0.6640\tCCC: 0.0672\n",
      "\n",
      "Test set: BoneAge loss: 1.3460, Gender loss: 0.0216, loss: 1.0149, CCC: 0.0190\n",
      "\n",
      "Test set: L1 loss: 1.3616,Round loss: 1.3614, Round2 loss: 1.3614, Round6: 1.3617, Gender: 0.0000\n",
      "\n",
      "Train ep: 65 [3835/9453 (3%)]\tBoneAge Loss: 0.8732\tGender Loss: 0.0216\t Loss: 0.6603\tCCC: 0.0691\n",
      "\n",
      "Test set: BoneAge loss: 1.2872, Gender loss: 0.0216, loss: 0.9708, CCC: 0.0121\n",
      "\n",
      "Test set: L1 loss: 1.3028,Round loss: 1.3027, Round2 loss: 1.3024, Round6: 1.3031, Gender: 0.0000\n",
      "\n",
      "Train ep: 66 [3835/9453 (3%)]\tBoneAge Loss: 0.8519\tGender Loss: 0.0216\t Loss: 0.6444\tCCC: 0.0718\n",
      "\n",
      "Test set: BoneAge loss: 1.3030, Gender loss: 0.0216, loss: 0.9827, CCC: 0.0164\n",
      "\n",
      "Test set: L1 loss: 1.3186,Round loss: 1.3185, Round2 loss: 1.3186, Round6: 1.3177, Gender: 0.0000\n",
      "\n",
      "Train ep: 67 [3835/9453 (3%)]\tBoneAge Loss: 0.8482\tGender Loss: 0.0216\t Loss: 0.6415\tCCC: 0.0752\n",
      "\n",
      "Test set: BoneAge loss: 1.3212, Gender loss: 0.0216, loss: 0.9963, CCC: 0.0171\n",
      "\n",
      "Test set: L1 loss: 1.3368,Round loss: 1.3368, Round2 loss: 1.3370, Round6: 1.3358, Gender: 0.0000\n",
      "\n",
      "Train ep: 68 [3835/9453 (3%)]\tBoneAge Loss: 0.8599\tGender Loss: 0.0216\t Loss: 0.6503\tCCC: 0.0711\n",
      "\n",
      "Test set: BoneAge loss: 1.3153, Gender loss: 0.0216, loss: 0.9919, CCC: 0.0165\n",
      "\n",
      "Test set: L1 loss: 1.3309,Round loss: 1.3311, Round2 loss: 1.3309, Round6: 1.3290, Gender: 0.0000\n",
      "\n",
      "Train ep: 69 [3835/9453 (3%)]\tBoneAge Loss: 0.8491\tGender Loss: 0.0216\t Loss: 0.6422\tCCC: 0.0741\n",
      "\n",
      "Test set: BoneAge loss: 1.3040, Gender loss: 0.0216, loss: 0.9834, CCC: 0.0182\n",
      "\n",
      "Test set: L1 loss: 1.3196,Round loss: 1.3193, Round2 loss: 1.3199, Round6: 1.3191, Gender: 0.0000\n",
      "\n",
      "Train ep: 70 [3835/9453 (3%)]\tBoneAge Loss: 0.8540\tGender Loss: 0.0216\t Loss: 0.6459\tCCC: 0.0725\n",
      "\n",
      "Test set: BoneAge loss: 1.3186, Gender loss: 0.0216, loss: 0.9943, CCC: 0.0179\n",
      "\n",
      "Test set: L1 loss: 1.3342,Round loss: 1.3340, Round2 loss: 1.3350, Round6: 1.3331, Gender: 0.0000\n",
      "\n",
      "Train ep: 71 [3835/9453 (3%)]\tBoneAge Loss: 0.8463\tGender Loss: 0.0216\t Loss: 0.6401\tCCC: 0.0759\n",
      "\n",
      "Test set: BoneAge loss: 1.3067, Gender loss: 0.0216, loss: 0.9854, CCC: 0.0175\n",
      "\n",
      "Test set: L1 loss: 1.3223,Round loss: 1.3225, Round2 loss: 1.3224, Round6: 1.3206, Gender: 0.0000\n",
      "\n",
      "Train ep: 72 [3835/9453 (3%)]\tBoneAge Loss: 0.8513\tGender Loss: 0.0216\t Loss: 0.6439\tCCC: 0.0739\n",
      "\n",
      "Test set: BoneAge loss: 1.3097, Gender loss: 0.0216, loss: 0.9877, CCC: 0.0170\n",
      "\n",
      "Test set: L1 loss: 1.3253,Round loss: 1.3255, Round2 loss: 1.3259, Round6: 1.3230, Gender: 0.0000\n",
      "\n",
      "Train ep: 73 [3835/9453 (3%)]\tBoneAge Loss: 0.8498\tGender Loss: 0.0216\t Loss: 0.6427\tCCC: 0.0741\n",
      "\n",
      "Test set: BoneAge loss: 1.3223, Gender loss: 0.0216, loss: 0.9971, CCC: 0.0179\n",
      "\n",
      "Test set: L1 loss: 1.3379,Round loss: 1.3380, Round2 loss: 1.3386, Round6: 1.3383, Gender: 0.0000\n",
      "\n",
      "Train ep: 74 [3835/9453 (3%)]\tBoneAge Loss: 0.8415\tGender Loss: 0.0216\t Loss: 0.6365\tCCC: 0.0770\n",
      "\n",
      "Test set: BoneAge loss: 1.3050, Gender loss: 0.0216, loss: 0.9841, CCC: 0.0184\n",
      "\n",
      "Test set: L1 loss: 1.3206,Round loss: 1.3205, Round2 loss: 1.3214, Round6: 1.3196, Gender: 0.0000\n",
      "\n",
      "Train ep: 75 [3835/9453 (3%)]\tBoneAge Loss: 0.8514\tGender Loss: 0.0216\t Loss: 0.6440\tCCC: 0.0750\n",
      "\n",
      "Test set: BoneAge loss: 1.3049, Gender loss: 0.0216, loss: 0.9840, CCC: 0.0163\n",
      "\n",
      "Test set: L1 loss: 1.3204,Round loss: 1.3208, Round2 loss: 1.3208, Round6: 1.3192, Gender: 0.0000\n",
      "\n",
      "Train ep: 76 [3835/9453 (3%)]\tBoneAge Loss: 0.8502\tGender Loss: 0.0216\t Loss: 0.6431\tCCC: 0.0733\n",
      "\n",
      "Test set: BoneAge loss: 1.3117, Gender loss: 0.0216, loss: 0.9892, CCC: 0.0182\n",
      "\n",
      "Test set: L1 loss: 1.3273,Round loss: 1.3273, Round2 loss: 1.3278, Round6: 1.3255, Gender: 0.0000\n",
      "\n",
      "Train ep: 77 [3835/9453 (3%)]\tBoneAge Loss: 0.8523\tGender Loss: 0.0216\t Loss: 0.6446\tCCC: 0.0735\n",
      "\n",
      "Test set: BoneAge loss: 1.3046, Gender loss: 0.0216, loss: 0.9839, CCC: 0.0165\n",
      "\n",
      "Test set: L1 loss: 1.3202,Round loss: 1.3205, Round2 loss: 1.3208, Round6: 1.3195, Gender: 0.0000\n",
      "\n",
      "Train ep: 78 [3835/9453 (3%)]\tBoneAge Loss: 0.8486\tGender Loss: 0.0216\t Loss: 0.6418\tCCC: 0.0744\n",
      "\n",
      "Test set: BoneAge loss: 1.3094, Gender loss: 0.0216, loss: 0.9875, CCC: 0.0173\n",
      "\n",
      "Test set: L1 loss: 1.3250,Round loss: 1.3251, Round2 loss: 1.3253, Round6: 1.3224, Gender: 0.0000\n",
      "\n",
      "Train ep: 79 [3835/9453 (3%)]\tBoneAge Loss: 0.8452\tGender Loss: 0.0216\t Loss: 0.6393\tCCC: 0.0754\n",
      "\n",
      "Test set: BoneAge loss: 1.3017, Gender loss: 0.0216, loss: 0.9817, CCC: 0.0165\n",
      "\n",
      "Test set: L1 loss: 1.3173,Round loss: 1.3175, Round2 loss: 1.3173, Round6: 1.3157, Gender: 0.0000\n",
      "\n",
      "Train ep: 80 [3835/9453 (3%)]\tBoneAge Loss: 0.8479\tGender Loss: 0.0216\t Loss: 0.6413\tCCC: 0.0724\n",
      "\n",
      "Test set: BoneAge loss: 1.3041, Gender loss: 0.0216, loss: 0.9835, CCC: 0.0170\n",
      "\n",
      "Test set: L1 loss: 1.3197,Round loss: 1.3200, Round2 loss: 1.3201, Round6: 1.3172, Gender: 0.0000\n",
      "\n",
      "Train ep: 81 [3835/9453 (3%)]\tBoneAge Loss: 0.8480\tGender Loss: 0.0216\t Loss: 0.6414\tCCC: 0.0744\n",
      "\n",
      "Test set: BoneAge loss: 1.3143, Gender loss: 0.0216, loss: 0.9911, CCC: 0.0182\n",
      "\n",
      "Test set: L1 loss: 1.3299,Round loss: 1.3297, Round2 loss: 1.3305, Round6: 1.3283, Gender: 0.0000\n",
      "\n",
      "Train ep: 82 [3835/9453 (3%)]\tBoneAge Loss: 0.8441\tGender Loss: 0.0216\t Loss: 0.6384\tCCC: 0.0755\n",
      "\n",
      "Test set: BoneAge loss: 1.3068, Gender loss: 0.0216, loss: 0.9855, CCC: 0.0179\n",
      "\n",
      "Test set: L1 loss: 1.3224,Round loss: 1.3228, Round2 loss: 1.3226, Round6: 1.3208, Gender: 0.0000\n",
      "\n",
      "Train ep: 83 [3835/9453 (3%)]\tBoneAge Loss: 0.8548\tGender Loss: 0.0216\t Loss: 0.6465\tCCC: 0.0743\n",
      "\n",
      "Test set: BoneAge loss: 1.3085, Gender loss: 0.0216, loss: 0.9867, CCC: 0.0156\n",
      "\n",
      "Test set: L1 loss: 1.3241,Round loss: 1.3241, Round2 loss: 1.3244, Round6: 1.3232, Gender: 0.0000\n",
      "\n",
      "Train ep: 84 [3835/9453 (3%)]\tBoneAge Loss: 0.8511\tGender Loss: 0.0216\t Loss: 0.6438\tCCC: 0.0743\n",
      "\n",
      "Test set: BoneAge loss: 1.3194, Gender loss: 0.0216, loss: 0.9950, CCC: 0.0165\n",
      "\n",
      "Test set: L1 loss: 1.3350,Round loss: 1.3349, Round2 loss: 1.3353, Round6: 1.3332, Gender: 0.0000\n",
      "\n",
      "Train ep: 85 [3835/9453 (3%)]\tBoneAge Loss: 0.8501\tGender Loss: 0.0216\t Loss: 0.6430\tCCC: 0.0739\n",
      "\n",
      "Test set: BoneAge loss: 1.3023, Gender loss: 0.0216, loss: 0.9822, CCC: 0.0177\n",
      "\n",
      "Test set: L1 loss: 1.3179,Round loss: 1.3183, Round2 loss: 1.3186, Round6: 1.3171, Gender: 0.0000\n",
      "\n",
      "Train ep: 86 [3835/9453 (3%)]\tBoneAge Loss: 0.8426\tGender Loss: 0.0216\t Loss: 0.6374\tCCC: 0.0767\n",
      "\n",
      "Test set: BoneAge loss: 1.3030, Gender loss: 0.0216, loss: 0.9827, CCC: 0.0162\n",
      "\n",
      "Test set: L1 loss: 1.3186,Round loss: 1.3188, Round2 loss: 1.3191, Round6: 1.3179, Gender: 0.0000\n",
      "\n",
      "Train ep: 87 [3835/9453 (3%)]\tBoneAge Loss: 0.8467\tGender Loss: 0.0216\t Loss: 0.6404\tCCC: 0.0738\n",
      "\n",
      "Test set: BoneAge loss: 1.3070, Gender loss: 0.0216, loss: 0.9857, CCC: 0.0176\n",
      "\n",
      "Test set: L1 loss: 1.3226,Round loss: 1.3229, Round2 loss: 1.3227, Round6: 1.3208, Gender: 0.0000\n",
      "\n",
      "Train ep: 88 [3835/9453 (3%)]\tBoneAge Loss: 0.8536\tGender Loss: 0.0216\t Loss: 0.6456\tCCC: 0.0731\n",
      "\n",
      "Test set: BoneAge loss: 1.3152, Gender loss: 0.0216, loss: 0.9918, CCC: 0.0175\n",
      "\n",
      "Test set: L1 loss: 1.3308,Round loss: 1.3308, Round2 loss: 1.3313, Round6: 1.3298, Gender: 0.0000\n",
      "\n",
      "Train ep: 89 [3835/9453 (3%)]\tBoneAge Loss: 0.8396\tGender Loss: 0.0216\t Loss: 0.6351\tCCC: 0.0767\n",
      "\n",
      "Test set: BoneAge loss: 1.3077, Gender loss: 0.0216, loss: 0.9862, CCC: 0.0170\n",
      "\n",
      "Test set: L1 loss: 1.3233,Round loss: 1.3235, Round2 loss: 1.3239, Round6: 1.3218, Gender: 0.0000\n",
      "\n",
      "Train ep: 90 [3835/9453 (3%)]\tBoneAge Loss: 0.8513\tGender Loss: 0.0216\t Loss: 0.6439\tCCC: 0.0742\n",
      "\n",
      "Test set: BoneAge loss: 1.3269, Gender loss: 0.0216, loss: 1.0006, CCC: 0.0188\n",
      "\n",
      "Test set: L1 loss: 1.3425,Round loss: 1.3423, Round2 loss: 1.3431, Round6: 1.3416, Gender: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ep: 91 [3835/9453 (3%)]\tBoneAge Loss: 0.8520\tGender Loss: 0.0216\t Loss: 0.6444\tCCC: 0.0740\n",
      "\n",
      "Test set: BoneAge loss: 1.2997, Gender loss: 0.0216, loss: 0.9802, CCC: 0.0172\n",
      "\n",
      "Test set: L1 loss: 1.3153,Round loss: 1.3150, Round2 loss: 1.3158, Round6: 1.3145, Gender: 0.0000\n",
      "\n",
      "Train ep: 92 [3835/9453 (3%)]\tBoneAge Loss: 0.8496\tGender Loss: 0.0216\t Loss: 0.6426\tCCC: 0.0750\n",
      "\n",
      "Test set: BoneAge loss: 1.3096, Gender loss: 0.0216, loss: 0.9876, CCC: 0.0173\n",
      "\n",
      "Test set: L1 loss: 1.3252,Round loss: 1.3254, Round2 loss: 1.3259, Round6: 1.3246, Gender: 0.0000\n",
      "\n",
      "Train ep: 93 [3835/9453 (3%)]\tBoneAge Loss: 0.8385\tGender Loss: 0.0216\t Loss: 0.6343\tCCC: 0.0772\n",
      "\n",
      "Test set: BoneAge loss: 1.3094, Gender loss: 0.0216, loss: 0.9875, CCC: 0.0171\n",
      "\n",
      "Test set: L1 loss: 1.3250,Round loss: 1.3255, Round2 loss: 1.3251, Round6: 1.3229, Gender: 0.0000\n",
      "\n",
      "Train ep: 94 [3835/9453 (3%)]\tBoneAge Loss: 0.8468\tGender Loss: 0.0216\t Loss: 0.6405\tCCC: 0.0756\n",
      "\n",
      "Test set: BoneAge loss: 1.3180, Gender loss: 0.0216, loss: 0.9939, CCC: 0.0169\n",
      "\n",
      "Test set: L1 loss: 1.3336,Round loss: 1.3339, Round2 loss: 1.3343, Round6: 1.3333, Gender: 0.0000\n",
      "\n",
      "Train ep: 95 [3835/9453 (3%)]\tBoneAge Loss: 0.8531\tGender Loss: 0.0216\t Loss: 0.6452\tCCC: 0.0737\n",
      "\n",
      "Test set: BoneAge loss: 1.3120, Gender loss: 0.0216, loss: 0.9894, CCC: 0.0170\n",
      "\n",
      "Test set: L1 loss: 1.3276,Round loss: 1.3280, Round2 loss: 1.3282, Round6: 1.3262, Gender: 0.0000\n",
      "\n",
      "Train ep: 96 [3835/9453 (3%)]\tBoneAge Loss: 0.8458\tGender Loss: 0.0216\t Loss: 0.6397\tCCC: 0.0743\n",
      "\n",
      "Test set: BoneAge loss: 1.3063, Gender loss: 0.0216, loss: 0.9852, CCC: 0.0167\n",
      "\n",
      "Test set: L1 loss: 1.3219,Round loss: 1.3222, Round2 loss: 1.3224, Round6: 1.3208, Gender: 0.0000\n",
      "\n",
      "Train ep: 97 [3835/9453 (3%)]\tBoneAge Loss: 0.8565\tGender Loss: 0.0216\t Loss: 0.6478\tCCC: 0.0733\n",
      "\n",
      "Test set: BoneAge loss: 1.3024, Gender loss: 0.0216, loss: 0.9822, CCC: 0.0172\n",
      "\n",
      "Test set: L1 loss: 1.3180,Round loss: 1.3180, Round2 loss: 1.3182, Round6: 1.3161, Gender: 0.0000\n",
      "\n",
      "Train ep: 98 [3835/9453 (3%)]\tBoneAge Loss: 0.8503\tGender Loss: 0.0216\t Loss: 0.6431\tCCC: 0.0741\n",
      "\n",
      "Test set: BoneAge loss: 1.2935, Gender loss: 0.0216, loss: 0.9755, CCC: 0.0164\n",
      "\n",
      "Test set: L1 loss: 1.3091,Round loss: 1.3091, Round2 loss: 1.3090, Round6: 1.3055, Gender: 0.0000\n",
      "\n",
      "Train ep: 99 [3835/9453 (3%)]\tBoneAge Loss: 0.8484\tGender Loss: 0.0216\t Loss: 0.6417\tCCC: 0.0743\n",
      "\n",
      "Test set: BoneAge loss: 1.3184, Gender loss: 0.0216, loss: 0.9942, CCC: 0.0170\n",
      "\n",
      "Test set: L1 loss: 1.3340,Round loss: 1.3341, Round2 loss: 1.3341, Round6: 1.3315, Gender: 0.0000\n",
      "\n",
      "Train ep: 100 [3835/9453 (3%)]\tBoneAge Loss: 0.8550\tGender Loss: 0.0216\t Loss: 0.6466\tCCC: 0.0731\n",
      "\n",
      "Test set: BoneAge loss: 1.3051, Gender loss: 0.0216, loss: 0.9843, CCC: 0.0168\n",
      "\n",
      "Test set: L1 loss: 1.3207,Round loss: 1.3207, Round2 loss: 1.3212, Round6: 1.3196, Gender: 0.0000\n",
      "\n",
      "Train ep: 101 [3835/9453 (3%)]\tBoneAge Loss: 0.8535\tGender Loss: 0.0216\t Loss: 0.6455\tCCC: 0.0744\n",
      "\n",
      "Test set: BoneAge loss: 1.3097, Gender loss: 0.0216, loss: 0.9877, CCC: 0.0148\n",
      "\n",
      "Test set: L1 loss: 1.3253,Round loss: 1.3254, Round2 loss: 1.3259, Round6: 1.3248, Gender: 0.0000\n",
      "\n",
      "Train ep: 102 [3835/9453 (3%)]\tBoneAge Loss: 0.8482\tGender Loss: 0.0216\t Loss: 0.6416\tCCC: 0.0742\n",
      "\n",
      "Test set: BoneAge loss: 1.3071, Gender loss: 0.0216, loss: 0.9857, CCC: 0.0168\n",
      "\n",
      "Test set: L1 loss: 1.3227,Round loss: 1.3230, Round2 loss: 1.3232, Round6: 1.3218, Gender: 0.0000\n",
      "\n",
      "Train ep: 103 [3835/9453 (3%)]\tBoneAge Loss: 0.8470\tGender Loss: 0.0216\t Loss: 0.6407\tCCC: 0.0745\n",
      "\n",
      "Test set: BoneAge loss: 1.3139, Gender loss: 0.0216, loss: 0.9908, CCC: 0.0170\n",
      "\n",
      "Test set: L1 loss: 1.3295,Round loss: 1.3295, Round2 loss: 1.3298, Round6: 1.3282, Gender: 0.0000\n",
      "\n",
      "Train ep: 104 [3835/9453 (3%)]\tBoneAge Loss: 0.8518\tGender Loss: 0.0216\t Loss: 0.6443\tCCC: 0.0739\n",
      "\n",
      "Test set: BoneAge loss: 1.3138, Gender loss: 0.0216, loss: 0.9907, CCC: 0.0167\n",
      "\n",
      "Test set: L1 loss: 1.3294,Round loss: 1.3295, Round2 loss: 1.3295, Round6: 1.3289, Gender: 0.0000\n",
      "\n",
      "Train ep: 105 [3835/9453 (3%)]\tBoneAge Loss: 0.8454\tGender Loss: 0.0216\t Loss: 0.6395\tCCC: 0.0749\n",
      "\n",
      "Test set: BoneAge loss: 1.3143, Gender loss: 0.0216, loss: 0.9912, CCC: 0.0177\n",
      "\n",
      "Test set: L1 loss: 1.3299,Round loss: 1.3299, Round2 loss: 1.3307, Round6: 1.3280, Gender: 0.0000\n",
      "\n",
      "Train ep: 106 [3835/9453 (3%)]\tBoneAge Loss: 0.8435\tGender Loss: 0.0216\t Loss: 0.6381\tCCC: 0.0758\n",
      "\n",
      "Test set: BoneAge loss: 1.3035, Gender loss: 0.0216, loss: 0.9830, CCC: 0.0188\n",
      "\n",
      "Test set: L1 loss: 1.3191,Round loss: 1.3192, Round2 loss: 1.3194, Round6: 1.3174, Gender: 0.0000\n",
      "\n",
      "Train ep: 107 [3835/9453 (3%)]\tBoneAge Loss: 0.8440\tGender Loss: 0.0216\t Loss: 0.6384\tCCC: 0.0758\n",
      "\n",
      "Test set: BoneAge loss: 1.3100, Gender loss: 0.0216, loss: 0.9879, CCC: 0.0167\n",
      "\n",
      "Test set: L1 loss: 1.3256,Round loss: 1.3257, Round2 loss: 1.3256, Round6: 1.3243, Gender: 0.0000\n",
      "\n",
      "Train ep: 108 [3835/9453 (3%)]\tBoneAge Loss: 0.8525\tGender Loss: 0.0216\t Loss: 0.6448\tCCC: 0.0746\n",
      "\n",
      "Test set: BoneAge loss: 1.3048, Gender loss: 0.0216, loss: 0.9840, CCC: 0.0172\n",
      "\n",
      "Test set: L1 loss: 1.3204,Round loss: 1.3205, Round2 loss: 1.3210, Round6: 1.3202, Gender: 0.0000\n",
      "\n",
      "Train ep: 109 [3835/9453 (3%)]\tBoneAge Loss: 0.8472\tGender Loss: 0.0216\t Loss: 0.6408\tCCC: 0.0750\n",
      "\n",
      "Test set: BoneAge loss: 1.3093, Gender loss: 0.0216, loss: 0.9874, CCC: 0.0165\n",
      "\n",
      "Test set: L1 loss: 1.3249,Round loss: 1.3249, Round2 loss: 1.3254, Round6: 1.3232, Gender: 0.0000\n",
      "\n",
      "Train ep: 110 [3835/9453 (3%)]\tBoneAge Loss: 0.8470\tGender Loss: 0.0216\t Loss: 0.6407\tCCC: 0.0736\n",
      "\n",
      "Test set: BoneAge loss: 1.3049, Gender loss: 0.0216, loss: 0.9841, CCC: 0.0175\n",
      "\n",
      "Test set: L1 loss: 1.3205,Round loss: 1.3206, Round2 loss: 1.3207, Round6: 1.3181, Gender: 0.0000\n",
      "\n",
      "Train ep: 111 [3835/9453 (3%)]\tBoneAge Loss: 0.8487\tGender Loss: 0.0216\t Loss: 0.6419\tCCC: 0.0745\n",
      "\n",
      "Test set: BoneAge loss: 1.3122, Gender loss: 0.0216, loss: 0.9895, CCC: 0.0172\n",
      "\n",
      "Test set: L1 loss: 1.3278,Round loss: 1.3281, Round2 loss: 1.3276, Round6: 1.3257, Gender: 0.0000\n",
      "\n",
      "Train ep: 112 [3835/9453 (3%)]\tBoneAge Loss: 0.8510\tGender Loss: 0.0216\t Loss: 0.6437\tCCC: 0.0745\n",
      "\n",
      "Test set: BoneAge loss: 1.3039, Gender loss: 0.0216, loss: 0.9833, CCC: 0.0157\n",
      "\n",
      "Test set: L1 loss: 1.3195,Round loss: 1.3195, Round2 loss: 1.3193, Round6: 1.3176, Gender: 0.0000\n",
      "\n",
      "Train ep: 113 [3835/9453 (3%)]\tBoneAge Loss: 0.8532\tGender Loss: 0.0216\t Loss: 0.6453\tCCC: 0.0732\n",
      "\n",
      "Test set: BoneAge loss: 1.3054, Gender loss: 0.0216, loss: 0.9844, CCC: 0.0162\n",
      "\n",
      "Test set: L1 loss: 1.3210,Round loss: 1.3211, Round2 loss: 1.3214, Round6: 1.3199, Gender: 0.0000\n",
      "\n",
      "Train ep: 114 [3835/9453 (3%)]\tBoneAge Loss: 0.8504\tGender Loss: 0.0216\t Loss: 0.6432\tCCC: 0.0747\n",
      "\n",
      "Test set: BoneAge loss: 1.3162, Gender loss: 0.0216, loss: 0.9926, CCC: 0.0164\n",
      "\n",
      "Test set: L1 loss: 1.3318,Round loss: 1.3321, Round2 loss: 1.3316, Round6: 1.3297, Gender: 0.0000\n",
      "\n",
      "Train ep: 115 [3835/9453 (3%)]\tBoneAge Loss: 0.8485\tGender Loss: 0.0216\t Loss: 0.6417\tCCC: 0.0741\n",
      "\n",
      "Test set: BoneAge loss: 1.3040, Gender loss: 0.0216, loss: 0.9834, CCC: 0.0171\n",
      "\n",
      "Test set: L1 loss: 1.3196,Round loss: 1.3199, Round2 loss: 1.3197, Round6: 1.3186, Gender: 0.0000\n",
      "\n",
      "Train ep: 116 [3835/9453 (3%)]\tBoneAge Loss: 0.8415\tGender Loss: 0.0216\t Loss: 0.6365\tCCC: 0.0772\n",
      "\n",
      "Test set: BoneAge loss: 1.3075, Gender loss: 0.0216, loss: 0.9861, CCC: 0.0165\n",
      "\n",
      "Test set: L1 loss: 1.3232,Round loss: 1.3232, Round2 loss: 1.3238, Round6: 1.3214, Gender: 0.0000\n",
      "\n",
      "Train ep: 117 [3835/9453 (3%)]\tBoneAge Loss: 0.8469\tGender Loss: 0.0216\t Loss: 0.6406\tCCC: 0.0752\n",
      "\n",
      "Test set: BoneAge loss: 1.3083, Gender loss: 0.0216, loss: 0.9866, CCC: 0.0171\n",
      "\n",
      "Test set: L1 loss: 1.3239,Round loss: 1.3240, Round2 loss: 1.3238, Round6: 1.3227, Gender: 0.0000\n",
      "\n",
      "Train ep: 118 [3835/9453 (3%)]\tBoneAge Loss: 0.8546\tGender Loss: 0.0216\t Loss: 0.6464\tCCC: 0.0731\n",
      "\n",
      "Test set: BoneAge loss: 1.3034, Gender loss: 0.0216, loss: 0.9830, CCC: 0.0162\n",
      "\n",
      "Test set: L1 loss: 1.3190,Round loss: 1.3191, Round2 loss: 1.3194, Round6: 1.3178, Gender: 0.0000\n",
      "\n",
      "Train ep: 119 [3835/9453 (3%)]\tBoneAge Loss: 0.8403\tGender Loss: 0.0216\t Loss: 0.6356\tCCC: 0.0764\n",
      "\n",
      "Test set: BoneAge loss: 1.3007, Gender loss: 0.0216, loss: 0.9809, CCC: 0.0151\n",
      "\n",
      "Test set: L1 loss: 1.3163,Round loss: 1.3165, Round2 loss: 1.3163, Round6: 1.3145, Gender: 0.0000\n",
      "\n",
      "Train ep: 120 [3835/9453 (3%)]\tBoneAge Loss: 0.8490\tGender Loss: 0.0216\t Loss: 0.6422\tCCC: 0.0731\n",
      "\n",
      "Test set: BoneAge loss: 1.3110, Gender loss: 0.0216, loss: 0.9886, CCC: 0.0177\n",
      "\n",
      "Test set: L1 loss: 1.3266,Round loss: 1.3267, Round2 loss: 1.3273, Round6: 1.3245, Gender: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ep: 121 [3835/9453 (3%)]\tBoneAge Loss: 0.8530\tGender Loss: 0.0216\t Loss: 0.6452\tCCC: 0.0739\n",
      "\n",
      "Test set: BoneAge loss: 1.3025, Gender loss: 0.0216, loss: 0.9823, CCC: 0.0163\n",
      "\n",
      "Test set: L1 loss: 1.3181,Round loss: 1.3182, Round2 loss: 1.3186, Round6: 1.3170, Gender: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "for epoch in range(61, 61+60 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/10-3-0845-nin-0fold-085-131.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ep: 121 [3835/9453 (3%)]\tBoneAge Loss: 0.8627\tGender Loss: 0.0216\t Loss: 0.6525\tCCC: 0.0720\n",
      "\n",
      "Test set: BoneAge loss: 1.3126, Gender loss: 0.0216, loss: 0.9899, CCC: 0.0205\n",
      "\n",
      "Test set: L1 loss: 1.3282,Round loss: 1.3278, Round2 loss: 1.3278, Round6: 1.3248, Gender: 0.0000\n",
      "\n",
      "Train ep: 122 [3835/9453 (3%)]\tBoneAge Loss: 0.8526\tGender Loss: 0.0216\t Loss: 0.6449\tCCC: 0.0749\n",
      "\n",
      "Test set: BoneAge loss: 1.4653, Gender loss: 0.0216, loss: 1.1043, CCC: 0.0212\n",
      "\n",
      "Test set: L1 loss: 1.4809,Round loss: 1.4806, Round2 loss: 1.4825, Round6: 1.4846, Gender: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "for epoch in range(121, 121+60 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: BoneAge loss: 1.3295, Gender loss: 0.0216, loss: 1.0025, CCC: 0.0158\n",
      "\n",
      "Test set: L1 loss: 1.3451,Round loss: 1.3451, Round2 loss: 1.3452, Round6: 1.3464, Gender: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(dataloders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ep: 150 [3835/9453 (3%)]\tBoneAge Loss: 0.9657\tGender Loss: 0.0216\t Loss: 0.7297\tCCC: 0.0401\n",
      "\n",
      "Test set: BoneAge loss: 1.2380, Gender loss: 0.0216, loss: 0.9339, CCC: 0.0132\n",
      "\n",
      "Test set: L1 loss: 1.2536,Round loss: 1.2531, Round2 loss: 1.2534, Round6: 1.2542, Gender: 0.0000\n",
      "\n",
      "Train ep: 151 [3835/9453 (3%)]\tBoneAge Loss: 0.9573\tGender Loss: 0.0216\t Loss: 0.7233\tCCC: 0.0400\n",
      "\n",
      "Test set: BoneAge loss: 1.3258, Gender loss: 0.0216, loss: 0.9998, CCC: 0.0051\n",
      "\n",
      "Test set: L1 loss: 1.3414,Round loss: 1.3422, Round2 loss: 1.3418, Round6: 1.3219, Gender: 0.0000\n",
      "\n",
      "Train ep: 152 [3835/9453 (3%)]\tBoneAge Loss: 0.9457\tGender Loss: 0.0216\t Loss: 0.7147\tCCC: 0.0399\n",
      "\n",
      "Test set: BoneAge loss: 1.4564, Gender loss: 0.0216, loss: 1.0977, CCC: 0.0006\n",
      "\n",
      "Test set: L1 loss: 1.4718,Round loss: 1.4720, Round2 loss: 1.4720, Round6: 1.4504, Gender: 0.0000\n",
      "\n",
      "Train ep: 153 [3835/9453 (3%)]\tBoneAge Loss: 0.8936\tGender Loss: 0.0216\t Loss: 0.6756\tCCC: 0.0558\n",
      "\n",
      "Test set: BoneAge loss: 1.4139, Gender loss: 0.0216, loss: 1.0658, CCC: 0.0129\n",
      "\n",
      "Test set: L1 loss: 1.4295,Round loss: 1.4301, Round2 loss: 1.4307, Round6: 1.4329, Gender: 0.0000\n",
      "\n",
      "Train ep: 154 [3835/9453 (3%)]\tBoneAge Loss: 0.8794\tGender Loss: 0.0216\t Loss: 0.6650\tCCC: 0.0588\n",
      "\n",
      "Test set: BoneAge loss: 1.2925, Gender loss: 0.0216, loss: 0.9748, CCC: 0.0216\n",
      "\n",
      "Test set: L1 loss: 1.3082,Round loss: 1.3079, Round2 loss: 1.3084, Round6: 1.3068, Gender: 0.0000\n",
      "\n",
      "Train ep: 155 [3835/9453 (3%)]\tBoneAge Loss: 0.8748\tGender Loss: 0.0216\t Loss: 0.6615\tCCC: 0.0608\n",
      "\n",
      "Test set: BoneAge loss: 1.3058, Gender loss: 0.0216, loss: 0.9848, CCC: 0.0204\n",
      "\n",
      "Test set: L1 loss: 1.3215,Round loss: 1.3214, Round2 loss: 1.3215, Round6: 1.3195, Gender: 0.0000\n",
      "\n",
      "Train ep: 156 [3835/9453 (3%)]\tBoneAge Loss: 0.8518\tGender Loss: 0.0216\t Loss: 0.6442\tCCC: 0.0703\n",
      "\n",
      "Test set: BoneAge loss: 1.2872, Gender loss: 0.0216, loss: 0.9708, CCC: 0.0217\n",
      "\n",
      "Test set: L1 loss: 1.3028,Round loss: 1.3025, Round2 loss: 1.3037, Round6: 1.3012, Gender: 0.0000\n",
      "\n",
      "Train ep: 157 [3835/9453 (3%)]\tBoneAge Loss: 0.8480\tGender Loss: 0.0216\t Loss: 0.6414\tCCC: 0.0705\n",
      "\n",
      "Test set: BoneAge loss: 1.2991, Gender loss: 0.0216, loss: 0.9797, CCC: 0.0201\n",
      "\n",
      "Test set: L1 loss: 1.3147,Round loss: 1.3146, Round2 loss: 1.3144, Round6: 1.3105, Gender: 0.0000\n",
      "\n",
      "Train ep: 158 [3835/9453 (3%)]\tBoneAge Loss: 0.8571\tGender Loss: 0.0216\t Loss: 0.6482\tCCC: 0.0677\n",
      "\n",
      "Test set: BoneAge loss: 1.2835, Gender loss: 0.0216, loss: 0.9680, CCC: 0.0211\n",
      "\n",
      "Test set: L1 loss: 1.2991,Round loss: 1.2994, Round2 loss: 1.2981, Round6: 1.2952, Gender: 0.0000\n",
      "\n",
      "Train ep: 159 [3835/9453 (3%)]\tBoneAge Loss: 0.8484\tGender Loss: 0.0216\t Loss: 0.6417\tCCC: 0.0704\n",
      "\n",
      "Test set: BoneAge loss: 1.2842, Gender loss: 0.0216, loss: 0.9685, CCC: 0.0213\n",
      "\n",
      "Test set: L1 loss: 1.2998,Round loss: 1.3003, Round2 loss: 1.2990, Round6: 1.2963, Gender: 0.0000\n",
      "\n",
      "Train ep: 160 [3835/9453 (3%)]\tBoneAge Loss: 0.8545\tGender Loss: 0.0216\t Loss: 0.6463\tCCC: 0.0695\n",
      "\n",
      "Test set: BoneAge loss: 1.2759, Gender loss: 0.0216, loss: 0.9623, CCC: 0.0184\n",
      "\n",
      "Test set: L1 loss: 1.2915,Round loss: 1.2919, Round2 loss: 1.2910, Round6: 1.2886, Gender: 0.0000\n",
      "\n",
      "Train ep: 161 [3835/9453 (3%)]\tBoneAge Loss: 0.8500\tGender Loss: 0.0216\t Loss: 0.6429\tCCC: 0.0701\n",
      "\n",
      "Test set: BoneAge loss: 1.2766, Gender loss: 0.0216, loss: 0.9629, CCC: 0.0224\n",
      "\n",
      "Test set: L1 loss: 1.2923,Round loss: 1.2925, Round2 loss: 1.2912, Round6: 1.2883, Gender: 0.0000\n",
      "\n",
      "Train ep: 162 [3835/9453 (3%)]\tBoneAge Loss: 0.8529\tGender Loss: 0.0216\t Loss: 0.6451\tCCC: 0.0683\n",
      "\n",
      "Test set: BoneAge loss: 1.2721, Gender loss: 0.0216, loss: 0.9595, CCC: 0.0210\n",
      "\n",
      "Test set: L1 loss: 1.2877,Round loss: 1.2881, Round2 loss: 1.2873, Round6: 1.2869, Gender: 0.0000\n",
      "\n",
      "Train ep: 163 [3835/9453 (3%)]\tBoneAge Loss: 0.8535\tGender Loss: 0.0216\t Loss: 0.6455\tCCC: 0.0692\n",
      "\n",
      "Test set: BoneAge loss: 1.2745, Gender loss: 0.0216, loss: 0.9613, CCC: 0.0223\n",
      "\n",
      "Test set: L1 loss: 1.2901,Round loss: 1.2904, Round2 loss: 1.2893, Round6: 1.2871, Gender: 0.0000\n",
      "\n",
      "Train ep: 164 [3835/9453 (3%)]\tBoneAge Loss: 0.8440\tGender Loss: 0.0216\t Loss: 0.6384\tCCC: 0.0698\n",
      "\n",
      "Test set: BoneAge loss: 1.2905, Gender loss: 0.0216, loss: 0.9733, CCC: 0.0240\n",
      "\n",
      "Test set: L1 loss: 1.3061,Round loss: 1.3065, Round2 loss: 1.3049, Round6: 1.3033, Gender: 0.0000\n",
      "\n",
      "Train ep: 165 [3835/9453 (3%)]\tBoneAge Loss: 0.8534\tGender Loss: 0.0216\t Loss: 0.6454\tCCC: 0.0687\n",
      "\n",
      "Test set: BoneAge loss: 1.2827, Gender loss: 0.0216, loss: 0.9674, CCC: 0.0210\n",
      "\n",
      "Test set: L1 loss: 1.2983,Round loss: 1.2987, Round2 loss: 1.2980, Round6: 1.2956, Gender: 0.0000\n",
      "\n",
      "Train ep: 166 [3835/9453 (3%)]\tBoneAge Loss: 0.8438\tGender Loss: 0.0216\t Loss: 0.6382\tCCC: 0.0701\n",
      "\n",
      "Test set: BoneAge loss: 1.2772, Gender loss: 0.0216, loss: 0.9633, CCC: 0.0212\n",
      "\n",
      "Test set: L1 loss: 1.2928,Round loss: 1.2932, Round2 loss: 1.2922, Round6: 1.2899, Gender: 0.0000\n",
      "\n",
      "Train ep: 167 [3835/9453 (3%)]\tBoneAge Loss: 0.8451\tGender Loss: 0.0216\t Loss: 0.6392\tCCC: 0.0708\n",
      "\n",
      "Test set: BoneAge loss: 1.2685, Gender loss: 0.0216, loss: 0.9568, CCC: 0.0218\n",
      "\n",
      "Test set: L1 loss: 1.2841,Round loss: 1.2844, Round2 loss: 1.2833, Round6: 1.2805, Gender: 0.0000\n",
      "\n",
      "Train ep: 168 [3835/9453 (3%)]\tBoneAge Loss: 0.8540\tGender Loss: 0.0216\t Loss: 0.6459\tCCC: 0.0697\n",
      "\n",
      "Test set: BoneAge loss: 1.2717, Gender loss: 0.0216, loss: 0.9592, CCC: 0.0220\n",
      "\n",
      "Test set: L1 loss: 1.2874,Round loss: 1.2875, Round2 loss: 1.2868, Round6: 1.2840, Gender: 0.0000\n",
      "\n",
      "Train ep: 169 [3835/9453 (3%)]\tBoneAge Loss: 0.8528\tGender Loss: 0.0216\t Loss: 0.6450\tCCC: 0.0677\n",
      "\n",
      "Test set: BoneAge loss: 1.2811, Gender loss: 0.0216, loss: 0.9662, CCC: 0.0240\n",
      "\n",
      "Test set: L1 loss: 1.2967,Round loss: 1.2972, Round2 loss: 1.2958, Round6: 1.2947, Gender: 0.0000\n",
      "\n",
      "Train ep: 170 [3835/9453 (3%)]\tBoneAge Loss: 0.8473\tGender Loss: 0.0216\t Loss: 0.6409\tCCC: 0.0695\n",
      "\n",
      "Test set: BoneAge loss: 1.2840, Gender loss: 0.0216, loss: 0.9684, CCC: 0.0229\n",
      "\n",
      "Test set: L1 loss: 1.2996,Round loss: 1.3000, Round2 loss: 1.2987, Round6: 1.2952, Gender: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "for epoch in range(150, 150+20 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ep: 170 [3835/9453 (3%)]\tBoneAge Loss: 0.8422\tGender Loss: 0.0216\t Loss: 0.6370\tCCC: 0.0715\n",
      "\n",
      "Test set: BoneAge loss: 1.3370, Gender loss: 0.0216, loss: 1.0082, CCC: 0.0159\n",
      "\n",
      "Test set: L1 loss: 1.3526,Round loss: 1.3526, Round2 loss: 1.3526, Round6: 1.3497, Gender: 0.0000\n",
      "\n",
      "Train ep: 171 [3835/9453 (3%)]\tBoneAge Loss: 0.8348\tGender Loss: 0.0216\t Loss: 0.6315\tCCC: 0.0782\n",
      "\n",
      "Test set: BoneAge loss: 1.2850, Gender loss: 0.0216, loss: 0.9692, CCC: 0.0144\n",
      "\n",
      "Test set: L1 loss: 1.3006,Round loss: 1.3006, Round2 loss: 1.3005, Round6: 1.2997, Gender: 0.0000\n",
      "\n",
      "Train ep: 172 [3835/9453 (3%)]\tBoneAge Loss: 0.8313\tGender Loss: 0.0216\t Loss: 0.6289\tCCC: 0.0777\n",
      "\n",
      "Test set: BoneAge loss: 1.4696, Gender loss: 0.0216, loss: 1.1076, CCC: 0.0090\n",
      "\n",
      "Test set: L1 loss: 1.4852,Round loss: 1.4857, Round2 loss: 1.4857, Round6: 1.4863, Gender: 0.0000\n",
      "\n",
      "Train ep: 173 [3835/9453 (3%)]\tBoneAge Loss: 0.8251\tGender Loss: 0.0216\t Loss: 0.6242\tCCC: 0.0781\n",
      "\n",
      "Test set: BoneAge loss: 1.3676, Gender loss: 0.0216, loss: 1.0311, CCC: 0.0146\n",
      "\n",
      "Test set: L1 loss: 1.3832,Round loss: 1.3833, Round2 loss: 1.3837, Round6: 1.3857, Gender: 0.0000\n",
      "\n",
      "Train ep: 174 [3835/9453 (3%)]\tBoneAge Loss: 0.8166\tGender Loss: 0.0216\t Loss: 0.6179\tCCC: 0.0819\n",
      "\n",
      "Test set: BoneAge loss: 1.3635, Gender loss: 0.0216, loss: 1.0280, CCC: 0.0147\n",
      "\n",
      "Test set: L1 loss: 1.3791,Round loss: 1.3791, Round2 loss: 1.3793, Round6: 1.3797, Gender: 0.0000\n",
      "\n",
      "Train ep: 175 [3835/9453 (3%)]\tBoneAge Loss: 0.8134\tGender Loss: 0.0216\t Loss: 0.6155\tCCC: 0.0811\n",
      "\n",
      "Test set: BoneAge loss: 1.3548, Gender loss: 0.0216, loss: 1.0215, CCC: 0.0171\n",
      "\n",
      "Test set: L1 loss: 1.3704,Round loss: 1.3702, Round2 loss: 1.3697, Round6: 1.3701, Gender: 0.0000\n",
      "\n",
      "Train ep: 176 [3835/9453 (3%)]\tBoneAge Loss: 0.8173\tGender Loss: 0.0216\t Loss: 0.6183\tCCC: 0.0812\n",
      "\n",
      "Test set: BoneAge loss: 1.3568, Gender loss: 0.0216, loss: 1.0230, CCC: 0.0154\n",
      "\n",
      "Test set: L1 loss: 1.3724,Round loss: 1.3719, Round2 loss: 1.3717, Round6: 1.3726, Gender: 0.0000\n",
      "\n",
      "Train ep: 177 [3835/9453 (3%)]\tBoneAge Loss: 0.8053\tGender Loss: 0.0216\t Loss: 0.6094\tCCC: 0.0837\n",
      "\n",
      "Test set: BoneAge loss: 1.3577, Gender loss: 0.0216, loss: 1.0237, CCC: 0.0166\n",
      "\n",
      "Test set: L1 loss: 1.3733,Round loss: 1.3729, Round2 loss: 1.3726, Round6: 1.3736, Gender: 0.0000\n",
      "\n",
      "Train ep: 178 [3835/9453 (3%)]\tBoneAge Loss: 0.8165\tGender Loss: 0.0216\t Loss: 0.6178\tCCC: 0.0843\n",
      "\n",
      "Test set: BoneAge loss: 1.3546, Gender loss: 0.0216, loss: 1.0213, CCC: 0.0158\n",
      "\n",
      "Test set: L1 loss: 1.3702,Round loss: 1.3697, Round2 loss: 1.3695, Round6: 1.3707, Gender: 0.0000\n",
      "\n",
      "Train ep: 179 [3835/9453 (3%)]\tBoneAge Loss: 0.8172\tGender Loss: 0.0216\t Loss: 0.6183\tCCC: 0.0817\n",
      "\n",
      "Test set: BoneAge loss: 1.3594, Gender loss: 0.0216, loss: 1.0250, CCC: 0.0166\n",
      "\n",
      "Test set: L1 loss: 1.3750,Round loss: 1.3744, Round2 loss: 1.3748, Round6: 1.3755, Gender: 0.0000\n",
      "\n",
      "Train ep: 180 [3835/9453 (3%)]\tBoneAge Loss: 0.8175\tGender Loss: 0.0216\t Loss: 0.6185\tCCC: 0.0806\n",
      "\n",
      "Test set: BoneAge loss: 1.3381, Gender loss: 0.0216, loss: 1.0090, CCC: 0.0157\n",
      "\n",
      "Test set: L1 loss: 1.3537,Round loss: 1.3534, Round2 loss: 1.3534, Round6: 1.3552, Gender: 0.0000\n",
      "\n",
      "Train ep: 181 [3835/9453 (3%)]\tBoneAge Loss: 0.8165\tGender Loss: 0.0216\t Loss: 0.6178\tCCC: 0.0819\n",
      "\n",
      "Test set: BoneAge loss: 1.3475, Gender loss: 0.0216, loss: 1.0160, CCC: 0.0164\n",
      "\n",
      "Test set: L1 loss: 1.3631,Round loss: 1.3628, Round2 loss: 1.3625, Round6: 1.3659, Gender: 0.0000\n",
      "\n",
      "Train ep: 182 [3835/9453 (3%)]\tBoneAge Loss: 0.8187\tGender Loss: 0.0216\t Loss: 0.6195\tCCC: 0.0826\n",
      "\n",
      "Test set: BoneAge loss: 1.3482, Gender loss: 0.0216, loss: 1.0166, CCC: 0.0174\n",
      "\n",
      "Test set: L1 loss: 1.3638,Round loss: 1.3632, Round2 loss: 1.3631, Round6: 1.3666, Gender: 0.0000\n",
      "\n",
      "Train ep: 183 [3835/9453 (3%)]\tBoneAge Loss: 0.8112\tGender Loss: 0.0216\t Loss: 0.6138\tCCC: 0.0832\n",
      "\n",
      "Test set: BoneAge loss: 1.3364, Gender loss: 0.0216, loss: 1.0077, CCC: 0.0168\n",
      "\n",
      "Test set: L1 loss: 1.3520,Round loss: 1.3515, Round2 loss: 1.3513, Round6: 1.3526, Gender: 0.0000\n",
      "\n",
      "Train ep: 184 [3835/9453 (3%)]\tBoneAge Loss: 0.8050\tGender Loss: 0.0216\t Loss: 0.6092\tCCC: 0.0836\n",
      "\n",
      "Test set: BoneAge loss: 1.3555, Gender loss: 0.0216, loss: 1.0221, CCC: 0.0167\n",
      "\n",
      "Test set: L1 loss: 1.3712,Round loss: 1.3709, Round2 loss: 1.3702, Round6: 1.3703, Gender: 0.0000\n",
      "\n",
      "Train ep: 185 [3835/9453 (3%)]\tBoneAge Loss: 0.8027\tGender Loss: 0.0216\t Loss: 0.6074\tCCC: 0.0844\n",
      "\n",
      "Test set: BoneAge loss: 1.3588, Gender loss: 0.0216, loss: 1.0245, CCC: 0.0145\n",
      "\n",
      "Test set: L1 loss: 1.3744,Round loss: 1.3738, Round2 loss: 1.3739, Round6: 1.3749, Gender: 0.0000\n",
      "\n",
      "Train ep: 186 [3835/9453 (3%)]\tBoneAge Loss: 0.8084\tGender Loss: 0.0216\t Loss: 0.6117\tCCC: 0.0843\n",
      "\n",
      "Test set: BoneAge loss: 1.3541, Gender loss: 0.0216, loss: 1.0210, CCC: 0.0165\n",
      "\n",
      "Test set: L1 loss: 1.3697,Round loss: 1.3693, Round2 loss: 1.3690, Round6: 1.3700, Gender: 0.0000\n",
      "\n",
      "Train ep: 187 [3835/9453 (3%)]\tBoneAge Loss: 0.8118\tGender Loss: 0.0216\t Loss: 0.6143\tCCC: 0.0805\n",
      "\n",
      "Test set: BoneAge loss: 1.3517, Gender loss: 0.0216, loss: 1.0192, CCC: 0.0154\n",
      "\n",
      "Test set: L1 loss: 1.3673,Round loss: 1.3668, Round2 loss: 1.3668, Round6: 1.3671, Gender: 0.0000\n",
      "\n",
      "Train ep: 188 [3835/9453 (3%)]\tBoneAge Loss: 0.8167\tGender Loss: 0.0216\t Loss: 0.6179\tCCC: 0.0810\n",
      "\n",
      "Test set: BoneAge loss: 1.3406, Gender loss: 0.0216, loss: 1.0109, CCC: 0.0156\n",
      "\n",
      "Test set: L1 loss: 1.3563,Round loss: 1.3559, Round2 loss: 1.3555, Round6: 1.3572, Gender: 0.0000\n",
      "\n",
      "Train ep: 189 [3835/9453 (3%)]\tBoneAge Loss: 0.8056\tGender Loss: 0.0216\t Loss: 0.6096\tCCC: 0.0838\n",
      "\n",
      "Test set: BoneAge loss: 1.3420, Gender loss: 0.0216, loss: 1.0119, CCC: 0.0171\n",
      "\n",
      "Test set: L1 loss: 1.3576,Round loss: 1.3569, Round2 loss: 1.3573, Round6: 1.3596, Gender: 0.0000\n",
      "\n",
      "Train ep: 190 [3835/9453 (3%)]\tBoneAge Loss: 0.8037\tGender Loss: 0.0216\t Loss: 0.6081\tCCC: 0.0869\n",
      "\n",
      "Test set: BoneAge loss: 1.3572, Gender loss: 0.0216, loss: 1.0233, CCC: 0.0160\n",
      "\n",
      "Test set: L1 loss: 1.3728,Round loss: 1.3723, Round2 loss: 1.3719, Round6: 1.3744, Gender: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "for epoch in range(170, 170+20 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ep: 190 [3835/9453 (3%)]\tBoneAge Loss: 0.9402\tGender Loss: 0.0216\t Loss: 0.7106\tCCC: 0.0439\n",
      "\n",
      "Test set: BoneAge loss: 1.3529, Gender loss: 0.0216, loss: 1.0201, CCC: 0.0061\n",
      "\n",
      "Test set: L1 loss: 1.3685,Round loss: 1.3652, Round2 loss: 1.3653, Round6: 1.3446, Gender: 0.0000\n",
      "\n",
      "Train ep: 191 [3835/9453 (3%)]\tBoneAge Loss: 0.9251\tGender Loss: 0.0216\t Loss: 0.6992\tCCC: 0.0438\n",
      "\n",
      "Test set: BoneAge loss: 1.4186, Gender loss: 0.0216, loss: 1.0693, CCC: 0.0072\n",
      "\n",
      "Test set: L1 loss: 1.4342,Round loss: 1.4336, Round2 loss: 1.4334, Round6: 1.4339, Gender: 0.0000\n",
      "\n",
      "Train ep: 192 [3835/9453 (3%)]\tBoneAge Loss: 0.8672\tGender Loss: 0.0216\t Loss: 0.6558\tCCC: 0.0591\n",
      "\n",
      "Test set: BoneAge loss: 1.1529, Gender loss: 0.0216, loss: 0.8701, CCC: 0.0320\n",
      "\n",
      "Test set: L1 loss: 1.1685,Round loss: 1.1685, Round2 loss: 1.1689, Round6: 1.1681, Gender: 0.0000\n",
      "\n",
      "Train ep: 193 [3835/9453 (3%)]\tBoneAge Loss: 0.8417\tGender Loss: 0.0216\t Loss: 0.6367\tCCC: 0.0701\n",
      "\n",
      "Test set: BoneAge loss: 1.1581, Gender loss: 0.0216, loss: 0.8740, CCC: 0.0303\n",
      "\n",
      "Test set: L1 loss: 1.1737,Round loss: 1.1733, Round2 loss: 1.1729, Round6: 1.1729, Gender: 0.0000\n",
      "\n",
      "Train ep: 194 [3835/9453 (3%)]\tBoneAge Loss: 0.8271\tGender Loss: 0.0216\t Loss: 0.6257\tCCC: 0.0725\n",
      "\n",
      "Test set: BoneAge loss: 1.1996, Gender loss: 0.0216, loss: 0.9051, CCC: 0.0303\n",
      "\n",
      "Test set: L1 loss: 1.2152,Round loss: 1.2153, Round2 loss: 1.2145, Round6: 1.2158, Gender: 0.0000\n",
      "\n",
      "Train ep: 195 [3835/9453 (3%)]\tBoneAge Loss: 0.8194\tGender Loss: 0.0216\t Loss: 0.6200\tCCC: 0.0752\n",
      "\n",
      "Test set: BoneAge loss: 1.1749, Gender loss: 0.0216, loss: 0.8866, CCC: 0.0309\n",
      "\n",
      "Test set: L1 loss: 1.1905,Round loss: 1.1904, Round2 loss: 1.1906, Round6: 1.1890, Gender: 0.0000\n",
      "\n",
      "Train ep: 196 [3835/9453 (3%)]\tBoneAge Loss: 0.8205\tGender Loss: 0.0216\t Loss: 0.6208\tCCC: 0.0755\n",
      "\n",
      "Test set: BoneAge loss: 1.1792, Gender loss: 0.0216, loss: 0.8898, CCC: 0.0322\n",
      "\n",
      "Test set: L1 loss: 1.1948,Round loss: 1.1949, Round2 loss: 1.1955, Round6: 1.1917, Gender: 0.0000\n",
      "\n",
      "Train ep: 197 [3835/9453 (3%)]\tBoneAge Loss: 0.8237\tGender Loss: 0.0216\t Loss: 0.6231\tCCC: 0.0753\n",
      "\n",
      "Test set: BoneAge loss: 1.1893, Gender loss: 0.0216, loss: 0.8974, CCC: 0.0309\n",
      "\n",
      "Test set: L1 loss: 1.2049,Round loss: 1.2054, Round2 loss: 1.2048, Round6: 1.2001, Gender: 0.0000\n",
      "\n",
      "Train ep: 198 [3835/9453 (3%)]\tBoneAge Loss: 0.8252\tGender Loss: 0.0216\t Loss: 0.6243\tCCC: 0.0738\n",
      "\n",
      "Test set: BoneAge loss: 1.1784, Gender loss: 0.0216, loss: 0.8892, CCC: 0.0319\n",
      "\n",
      "Test set: L1 loss: 1.1940,Round loss: 1.1941, Round2 loss: 1.1943, Round6: 1.1905, Gender: 0.0000\n",
      "\n",
      "Train ep: 199 [3835/9453 (3%)]\tBoneAge Loss: 0.8199\tGender Loss: 0.0216\t Loss: 0.6203\tCCC: 0.0763\n",
      "\n",
      "Test set: BoneAge loss: 1.1830, Gender loss: 0.0216, loss: 0.8927, CCC: 0.0296\n",
      "\n",
      "Test set: L1 loss: 1.1986,Round loss: 1.1988, Round2 loss: 1.1987, Round6: 1.1949, Gender: 0.0000\n",
      "\n",
      "Train ep: 200 [3835/9453 (3%)]\tBoneAge Loss: 0.8236\tGender Loss: 0.0216\t Loss: 0.6231\tCCC: 0.0757\n",
      "\n",
      "Test set: BoneAge loss: 1.1835, Gender loss: 0.0216, loss: 0.8930, CCC: 0.0309\n",
      "\n",
      "Test set: L1 loss: 1.1991,Round loss: 1.1990, Round2 loss: 1.1995, Round6: 1.1955, Gender: 0.0000\n",
      "\n",
      "Train ep: 201 [3835/9453 (3%)]\tBoneAge Loss: 0.8150\tGender Loss: 0.0216\t Loss: 0.6167\tCCC: 0.0775\n",
      "\n",
      "Test set: BoneAge loss: 1.1846, Gender loss: 0.0216, loss: 0.8939, CCC: 0.0309\n",
      "\n",
      "Test set: L1 loss: 1.2003,Round loss: 1.2005, Round2 loss: 1.2009, Round6: 1.1975, Gender: 0.0000\n",
      "\n",
      "Train ep: 202 [3835/9453 (3%)]\tBoneAge Loss: 0.8339\tGender Loss: 0.0216\t Loss: 0.6308\tCCC: 0.0722\n",
      "\n",
      "Test set: BoneAge loss: 1.1750, Gender loss: 0.0216, loss: 0.8867, CCC: 0.0318\n",
      "\n",
      "Test set: L1 loss: 1.1906,Round loss: 1.1907, Round2 loss: 1.1905, Round6: 1.1888, Gender: 0.0000\n",
      "\n",
      "Train ep: 203 [3835/9453 (3%)]\tBoneAge Loss: 0.8308\tGender Loss: 0.0216\t Loss: 0.6285\tCCC: 0.0742\n",
      "\n",
      "Test set: BoneAge loss: 1.1822, Gender loss: 0.0216, loss: 0.8920, CCC: 0.0322\n",
      "\n",
      "Test set: L1 loss: 1.1978,Round loss: 1.1979, Round2 loss: 1.1980, Round6: 1.1950, Gender: 0.0000\n",
      "\n",
      "Train ep: 204 [3835/9453 (3%)]\tBoneAge Loss: 0.8237\tGender Loss: 0.0216\t Loss: 0.6232\tCCC: 0.0751\n",
      "\n",
      "Test set: BoneAge loss: 1.1853, Gender loss: 0.0216, loss: 0.8944, CCC: 0.0326\n",
      "\n",
      "Test set: L1 loss: 1.2009,Round loss: 1.2009, Round2 loss: 1.2009, Round6: 1.1981, Gender: 0.0000\n",
      "\n",
      "Train ep: 205 [3835/9453 (3%)]\tBoneAge Loss: 0.8312\tGender Loss: 0.0216\t Loss: 0.6288\tCCC: 0.0748\n",
      "\n",
      "Test set: BoneAge loss: 1.1863, Gender loss: 0.0216, loss: 0.8951, CCC: 0.0321\n",
      "\n",
      "Test set: L1 loss: 1.2019,Round loss: 1.2021, Round2 loss: 1.2018, Round6: 1.1989, Gender: 0.0000\n",
      "\n",
      "Train ep: 206 [3835/9453 (3%)]\tBoneAge Loss: 0.8195\tGender Loss: 0.0216\t Loss: 0.6200\tCCC: 0.0771\n",
      "\n",
      "Test set: BoneAge loss: 1.1856, Gender loss: 0.0216, loss: 0.8946, CCC: 0.0299\n",
      "\n",
      "Test set: L1 loss: 1.2012,Round loss: 1.2015, Round2 loss: 1.2014, Round6: 1.1980, Gender: 0.0000\n",
      "\n",
      "Train ep: 207 [3835/9453 (3%)]\tBoneAge Loss: 0.8256\tGender Loss: 0.0216\t Loss: 0.6246\tCCC: 0.0751\n",
      "\n",
      "Test set: BoneAge loss: 1.1879, Gender loss: 0.0216, loss: 0.8963, CCC: 0.0301\n",
      "\n",
      "Test set: L1 loss: 1.2035,Round loss: 1.2038, Round2 loss: 1.2035, Round6: 1.1994, Gender: 0.0000\n",
      "\n",
      "Train ep: 208 [3835/9453 (3%)]\tBoneAge Loss: 0.8239\tGender Loss: 0.0216\t Loss: 0.6233\tCCC: 0.0747\n",
      "\n",
      "Test set: BoneAge loss: 1.1752, Gender loss: 0.0216, loss: 0.8868, CCC: 0.0321\n",
      "\n",
      "Test set: L1 loss: 1.1908,Round loss: 1.1910, Round2 loss: 1.1907, Round6: 1.1895, Gender: 0.0000\n",
      "\n",
      "Train ep: 209 [3835/9453 (3%)]\tBoneAge Loss: 0.8192\tGender Loss: 0.0216\t Loss: 0.6198\tCCC: 0.0758\n",
      "\n",
      "Test set: BoneAge loss: 1.1877, Gender loss: 0.0216, loss: 0.8962, CCC: 0.0317\n",
      "\n",
      "Test set: L1 loss: 1.2033,Round loss: 1.2038, Round2 loss: 1.2032, Round6: 1.2003, Gender: 0.0000\n",
      "\n",
      "Train ep: 210 [3835/9453 (3%)]\tBoneAge Loss: 0.8300\tGender Loss: 0.0216\t Loss: 0.6279\tCCC: 0.0731\n",
      "\n",
      "Test set: BoneAge loss: 1.1822, Gender loss: 0.0216, loss: 0.8920, CCC: 0.0312\n",
      "\n",
      "Test set: L1 loss: 1.1978,Round loss: 1.1981, Round2 loss: 1.1980, Round6: 1.1944, Gender: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "for epoch in range(190, 190+20 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/10-3-0300-nin-0fold-083-119.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ep: 210 [3835/9453 (3%)]\tBoneAge Loss: 0.8957\tGender Loss: 0.0216\t Loss: 0.6772\tCCC: 0.0560\n",
      "\n",
      "Test set: BoneAge loss: 1.4372, Gender loss: 0.0216, loss: 1.0833, CCC: 0.0082\n",
      "\n",
      "Test set: L1 loss: 1.4527,Round loss: 1.4553, Round2 loss: 1.4562, Round6: 1.4587, Gender: 0.0000\n",
      "\n",
      "Train ep: 211 [3835/9453 (3%)]\tBoneAge Loss: 0.8634\tGender Loss: 0.0216\t Loss: 0.6530\tCCC: 0.0599\n",
      "\n",
      "Test set: BoneAge loss: 1.1618, Gender loss: 0.0216, loss: 0.8768, CCC: 0.0306\n",
      "\n",
      "Test set: L1 loss: 1.1774,Round loss: 1.1779, Round2 loss: 1.1763, Round6: 1.1730, Gender: 0.0000\n",
      "\n",
      "Train ep: 212 [3835/9453 (3%)]\tBoneAge Loss: 0.8407\tGender Loss: 0.0216\t Loss: 0.6359\tCCC: 0.0660\n",
      "\n",
      "Test set: BoneAge loss: 1.1441, Gender loss: 0.0216, loss: 0.8635, CCC: 0.0286\n",
      "\n",
      "Test set: L1 loss: 1.1597,Round loss: 1.1595, Round2 loss: 1.1603, Round6: 1.1622, Gender: 0.0000\n",
      "\n",
      "Train ep: 213 [3835/9453 (3%)]\tBoneAge Loss: 0.8402\tGender Loss: 0.0216\t Loss: 0.6355\tCCC: 0.0664\n",
      "\n",
      "Test set: BoneAge loss: 1.1426, Gender loss: 0.0216, loss: 0.8623, CCC: 0.0295\n",
      "\n",
      "Test set: L1 loss: 1.1581,Round loss: 1.1578, Round2 loss: 1.1582, Round6: 1.1599, Gender: 0.0000\n",
      "\n",
      "Train ep: 214 [3835/9453 (3%)]\tBoneAge Loss: 0.8326\tGender Loss: 0.0216\t Loss: 0.6298\tCCC: 0.0688\n",
      "\n",
      "Test set: BoneAge loss: 1.1432, Gender loss: 0.0216, loss: 0.8628, CCC: 0.0309\n",
      "\n",
      "Test set: L1 loss: 1.1588,Round loss: 1.1587, Round2 loss: 1.1587, Round6: 1.1606, Gender: 0.0000\n",
      "\n",
      "Train ep: 215 [3835/9453 (3%)]\tBoneAge Loss: 0.8320\tGender Loss: 0.0216\t Loss: 0.6294\tCCC: 0.0699\n",
      "\n",
      "Test set: BoneAge loss: 1.1462, Gender loss: 0.0216, loss: 0.8651, CCC: 0.0286\n",
      "\n",
      "Test set: L1 loss: 1.1618,Round loss: 1.1615, Round2 loss: 1.1618, Round6: 1.1652, Gender: 0.0000\n",
      "\n",
      "Train ep: 216 [3835/9453 (3%)]\tBoneAge Loss: 0.8330\tGender Loss: 0.0216\t Loss: 0.6301\tCCC: 0.0683\n",
      "\n",
      "Test set: BoneAge loss: 1.1423, Gender loss: 0.0216, loss: 0.8622, CCC: 0.0308\n",
      "\n",
      "Test set: L1 loss: 1.1579,Round loss: 1.1576, Round2 loss: 1.1579, Round6: 1.1600, Gender: 0.0000\n",
      "\n",
      "Train ep: 217 [3835/9453 (3%)]\tBoneAge Loss: 0.8351\tGender Loss: 0.0216\t Loss: 0.6317\tCCC: 0.0674\n",
      "\n",
      "Test set: BoneAge loss: 1.1393, Gender loss: 0.0216, loss: 0.8599, CCC: 0.0300\n",
      "\n",
      "Test set: L1 loss: 1.1549,Round loss: 1.1547, Round2 loss: 1.1552, Round6: 1.1566, Gender: 0.0000\n",
      "\n",
      "Train ep: 218 [3835/9453 (3%)]\tBoneAge Loss: 0.8344\tGender Loss: 0.0216\t Loss: 0.6312\tCCC: 0.0681\n",
      "\n",
      "Test set: BoneAge loss: 1.1436, Gender loss: 0.0216, loss: 0.8631, CCC: 0.0307\n",
      "\n",
      "Test set: L1 loss: 1.1593,Round loss: 1.1589, Round2 loss: 1.1590, Round6: 1.1617, Gender: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "for epoch in range(210, 210+8 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/10-3-0320-nin-0fold-083-116.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../models/10-3-0320-nin-0fold-083-116.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(predict_loader):\n",
    "    model.eval()\n",
    "    pred_gender_loss = 0\n",
    "    predictions = []\n",
    "    \n",
    "    num_samp = len(predict_loader.dataset)\n",
    "    for sample in predict_loader:\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "\n",
    "        ba_output, g_output = model(data)\n",
    "    \n",
    "#         print(test_boneage_loss)\n",
    "        gender_loss = F.binary_cross_entropy_with_logits(g_output.view(-1), target[:,0])\n",
    "        pred_gender_loss += gender_loss.data[0]\n",
    "        \n",
    "        pred_labels = target[:,1].data.cpu().numpy()\n",
    "#         print(pred_labels.shape)\n",
    "        pred_bonage = ba_output.view(-1).data.cpu().numpy()\n",
    "#         print(pred_bonage.shape)\n",
    "        \n",
    "        predictions.append(np.column_stack((pred_labels, pred_bonage)))\n",
    "\n",
    "    print('\\nPrediction Gender loss: {:.4f}'.format(pred_gender_loss / num_samp))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1425.000000</td>\n",
       "      <td>1425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8678.919298</td>\n",
       "      <td>0.542456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4123.833964</td>\n",
       "      <td>0.498369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1386.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5196.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8784.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12147.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15612.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         male\n",
       "count   1425.000000  1425.000000\n",
       "mean    8678.919298     0.542456\n",
       "std     4123.833964     0.498369\n",
       "min     1386.000000     0.000000\n",
       "25%     5196.000000     0.000000\n",
       "50%     8784.000000     1.000000\n",
       "75%    12147.000000     1.000000\n",
       "max    15612.000000     1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = pd.read_csv(TEST_LABEL, dtype=int)\n",
    "pred_labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_image_dataset = BoneAgeDataset(TEST_DIR, pred_labels, FILETYPE, img_size, data_transforms['pred'], 'pred')\n",
    "pred_dataloder = torch.utils.data.DataLoader(pred_image_dataset, batch_size=32, shuffle=True, num_workers=24,\n",
    "                                             pin_memory=True)\n",
    "pred_dataset_size = len(pred_image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 1, 640, 640])\n",
      "0 0.238465481364\n",
      "1 torch.Size([32, 1, 640, 640])\n",
      "1 0.26067258119\n",
      "2 torch.Size([32, 1, 640, 640])\n",
      "2 0.252933594625\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample in enumerate(pred_dataloder):\n",
    "    print(i_batch, sample['image'].size())\n",
    "    print(i_batch, sample['image'].mean())\n",
    "#     for i in xrange(sample['image'].size()[0]):\n",
    "#         img = sample['image'][i,0,:,:].numpy()\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img, cmap=plt.cm.gray)\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Gender loss: 0.0218\n"
     ]
    }
   ],
   "source": [
    "preds = predict(pred_dataloder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_df = pd.DataFrame(np.vstack(tuple(preds)), columns=('id', 'boneage')).sort_values('id')\n",
    "all_preds_df['id'] = all_preds_df['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boneage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1386</td>\n",
       "      <td>86.842384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>1392</td>\n",
       "      <td>79.800110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1397</td>\n",
       "      <td>137.686981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>1401</td>\n",
       "      <td>98.267731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>1410</td>\n",
       "      <td>79.800110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     boneage\n",
       "37    1386   86.842384\n",
       "524   1392   79.800110\n",
       "226   1397  137.686981\n",
       "1337  1401   98.267731\n",
       "927   1410   79.800110"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boneage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>15592</td>\n",
       "      <td>95.326370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>15601</td>\n",
       "      <td>153.793701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>15607</td>\n",
       "      <td>172.908478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>15611</td>\n",
       "      <td>147.293030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>15612</td>\n",
       "      <td>141.046539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     boneage\n",
       "120   15592   95.326370\n",
       "1395  15601  153.793701\n",
       "1039  15607  172.908478\n",
       "74    15611  147.293030\n",
       "1195  15612  141.046539"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds_df.to_csv('../sub/10-3-0707-nin-0fold-083-116.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
