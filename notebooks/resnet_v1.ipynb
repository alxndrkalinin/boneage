{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TMP=\"/tmp\"\n",
      "env: JOBLIB_TEMP_FOLDER=\"/tmp\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline\n",
    "%env TMP=\"/tmp\"\n",
    "%env JOBLIB_TEMP_FOLDER=\"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def summary(input_size, model):\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            m_key = '%s-%i' % (class_name, module_idx+1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key]['input_shape'] = list(input[0].size())\n",
    "            summary[m_key]['input_shape'][0] = -1\n",
    "            summary[m_key]['output_shape'] = list(output.size())\n",
    "            summary[m_key]['output_shape'][0] = -1\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, 'weight'):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                if module.weight.requires_grad:\n",
    "                    summary[m_key]['trainable'] = True\n",
    "                else:\n",
    "                    summary[m_key]['trainable'] = False\n",
    "            if hasattr(module, 'bias'):\n",
    "                params +=  torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key]['nb_params'] = params\n",
    "\n",
    "        if not isinstance(module, nn.Sequential) and \\\n",
    "           not isinstance(module, nn.ModuleList) and \\\n",
    "           not (module == model):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    # check if there are multiple inputs to the network\n",
    "    if isinstance(input_size[0], (list, tuple)):\n",
    "        x = [Variable(torch.rand(1,*in_size)) for in_size in input_size]\n",
    "    else:\n",
    "        x = Variable(torch.rand(1,*input_size))\n",
    "\n",
    "    # create properties\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "    # make a forward pass\n",
    "    model(x)\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../data/boneage-training-dataset/'\n",
    "TRAIN_LABEL = '../data/train.csv'\n",
    "FILETYPE = '.png'\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BoneAgeDataset(Dataset):\n",
    "    \"\"\"Bone Age dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, labels, filetype, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.filetype = filetype\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, str(self.labels.iloc[idx]['id']) + self.filetype)\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        img = img.point(lambda x: x if x<200 else 0)\n",
    "#         print('PIL size:', img.size)\n",
    "        img = np.asarray(img)\n",
    "#         print('Np size: ',img.shape)\n",
    "        if img.shape[1] > img.shape[0]:\n",
    "#             print(img.shape)\n",
    "            img = np.swapaxes(img,0,1)\n",
    "        img = cv2.resize(img, (640,850))\n",
    "        img = img[210:,:]\n",
    "#         print(img.shape)\n",
    "        rot_ang = range(0,360,30)\n",
    "        rot_ang = rot_ang[np.random.randint(0,len(rot_ang))]\n",
    "#         print(rot_ang)\n",
    "        scale = np.random.uniform(0.8,1.2)\n",
    "#         print(scale)\n",
    "        rot_mat = cv2.getRotationMatrix2D((img.shape[0]/2,img.shape[1]/2), rot_ang, scale);\n",
    "        img = cv2.warpAffine(img, rot_mat, (img.shape[0],img.shape[1]))\n",
    "#         print(img.shape)\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        \n",
    "#         image = cv2.imread(img_name)[:,:,::-1]\n",
    "        boneage = self.labels.iloc[idx]['boneage'].astype(np.float32)\n",
    "        gender = self.labels.iloc[idx]['male'].astype(np.uint8)\n",
    "        \n",
    "        label = np.hstack((boneage, gender))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        sample = {'image': img, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale(320),\n",
    "#         transforms.CenterCrop(512),\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(320),\n",
    "#         transforms.CenterCrop(512),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(TRAIN_LABEL)\n",
    "bins = xrange(20)\n",
    "labels['bins'] = np.digitize(labels['boneage'], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/software/miniconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=4)\n",
    "splits = []\n",
    "for train, test in skf.split(np.zeros(len(labels)), labels['bins']):\n",
    "    fold_label = {\n",
    "        'train': labels.loc[train, ('id', 'boneage', 'male')],\n",
    "        'val': labels.loc[test, ('id', 'boneage', 'male')]\n",
    "    }\n",
    "    splits.append(fold_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_label = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_datasets = {x: BoneAgeDataset(TRAIN_DIR, fold_label[x], FILETYPE, data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=16, pin_memory=True)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([16, 3, 224, 224])\n",
      "0 -0.904783348563\n",
      "1 torch.Size([16, 3, 224, 224])\n",
      "1 -1.2249584799\n",
      "2 torch.Size([16, 3, 224, 224])\n",
      "2 -0.761572569647\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample in enumerate(dataloders['val']):\n",
    "    print(i_batch, sample['image'].size())\n",
    "    print(i_batch, sample['image'].mean())\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape=(3, 224, 224)):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.bn = nn.BatchNorm2d(input_shape[0])\n",
    "        resnet = models.resnet18(pretrained=False)\n",
    "        num_ftrs = resnet.fc.in_features\n",
    "        resnet.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "        self.resnet = resnet\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(self.bn(x))\n",
    "        return x\n",
    "    \n",
    "model = Net([3, 224, 224])\n",
    "    \n",
    "# print(summary([3, 224, 224], model))\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "# momentum = 0.9\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ccc(x, y):\n",
    "#     print('X:', x)\n",
    "    mean_x = torch.mean(x)\n",
    "#     print('Mean x:', mean_x)\n",
    "    mean_y = torch.mean(y)\n",
    "#     print('Mean y:', mean_y)\n",
    "    xm = x.sub(mean_x)\n",
    "    ym = y.sub(mean_y)\n",
    "    xn = torch.norm(xm, 2)\n",
    "#     print('Xn:', xn)\n",
    "    yn = torch.norm(ym, 2)\n",
    "#     print('Yn:', yn)\n",
    "    xydot = ym.dot(xm.view(-1))\n",
    "#     print('XYdot:', xydot)\n",
    "\n",
    "    ccc_num = 2 * xydot / xm.size()[0]\n",
    "#     print('CCC num:', ccc_num)\n",
    "    ccc_den = xn + yn + torch.pow(mean_x.sub(mean_y), 2)\n",
    "#     print('CCC den:', ccc_den)\n",
    "\n",
    "    ccc = ccc_num / ccc_den\n",
    "    return ccc\n",
    "    \n",
    "\n",
    "def train(epoch, train_loader):\n",
    "    exp_lr_scheduler.step()\n",
    "    model.train()\n",
    "    train_boneage_loss = 0\n",
    "    train_gender_loss = 0\n",
    "    train_loss = 0\n",
    "    train_ccc = 0\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        for i in xrange(output.size[0]):\n",
    "            if output[i,1] > 0.5:\n",
    "                output[i,0] = (output[i,0] // 6) * 6\n",
    "            else:\n",
    "                output[i,0] = (output[i,0] // 2) * 2\n",
    "        \n",
    "        boneage_loss = F.l1_loss(output[:,0], target[:,0])\n",
    "        train_boneage_loss += boneage_loss.data[0]\n",
    "        gender_loss = F.binary_cross_entropy(F.sigmoid(output[:,1]), target[:,1])\n",
    "        train_gender_loss += gender_loss.data[0]\n",
    "        loss = 0.8 * boneage_loss + 0.2 * gender_loss\n",
    "        train_loss += loss.data[0]\n",
    "        c = ccc(output[:,0], target[:,0])\n",
    "        train_ccc += c.data.cpu().numpy()[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % (1000 // len(target)) == 0:\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tBoneAge Loss: {:.4f}\\tGender Loss: {:.4f}\\t Loss: {:.4f}\\tCCC: {:.4f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader),\n",
    "        100. * batch_idx / len(train_loader), train_boneage_loss / len(train_loader),\n",
    "        train_gender_loss / len(train_loader), train_loss / len(train_loader),\n",
    "        train_ccc / len(train_loader)))\n",
    "\n",
    "def test(test_loader):\n",
    "    model.eval()\n",
    "    test_boneage_loss = 0\n",
    "    test_gender_loss = 0\n",
    "    test_loss = 0\n",
    "    test_ccc = 0\n",
    "    for sample in test_loader:\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        boneage_loss = F.l1_loss(output[:,0], target[:,0])\n",
    "        test_boneage_loss += boneage_loss.data[0]\n",
    "        gender_loss = F.binary_cross_entropy(F.sigmoid(output[:,1]), target[:,1])\n",
    "        test_gender_loss += gender_loss.data[0]\n",
    "        loss = 0.8 * boneage_loss + 0.2 * gender_loss\n",
    "        test_loss += loss.data[0]\n",
    "        c = ccc(output[:,0], target[:,0])\n",
    "        test_ccc += c.data.cpu().numpy()[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Avg BoneAge loss: {:.4f}, Avg Gender loss: {:.4f}, Avg loss: {:.4f} CCC: {:.4f}\\n'.format(\n",
    "        test_boneage_loss / len(test_loader), test_gender_loss / len(test_loader),\n",
    "        test_loss / len(test_loader), test_ccc / len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '../models/9-27-1540-resnet50-1fold-5.7889-2.56.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [7670/591 (100%)]\tBoneAge Loss: 33.7842\tGender Loss: 0.8518\t Loss: 68.4201\tCCC: 0.1757\n",
      "\n",
      "Test set: Avg BoneAge loss: 38.4368, Avg Gender loss: 1.0430, Avg loss: 0.0247 CCC: -0.1308\n",
      "\n",
      "Train Epoch: 2 [7670/591 (100%)]\tBoneAge Loss: 31.8530\tGender Loss: 0.8281\t Loss: 64.5340\tCCC: 0.5336\n",
      "\n",
      "Test set: Avg BoneAge loss: 38.8241, Avg Gender loss: 0.9699, Avg loss: 0.0249 CCC: 0.0745\n",
      "\n",
      "Train Epoch: 3 [7670/591 (100%)]\tBoneAge Loss: 31.3127\tGender Loss: 0.8128\t Loss: 63.4383\tCCC: 0.7426\n",
      "\n",
      "Test set: Avg BoneAge loss: 42.1918, Avg Gender loss: 0.7551, Avg loss: 0.0270 CCC: -0.4734\n",
      "\n",
      "Train Epoch: 4 [7670/591 (100%)]\tBoneAge Loss: 31.1219\tGender Loss: 0.7900\t Loss: 63.0339\tCCC: 0.8862\n",
      "\n",
      "Test set: Avg BoneAge loss: 44.8073, Avg Gender loss: 0.7096, Avg loss: 0.0286 CCC: -0.2974\n",
      "\n",
      "Train Epoch: 5 [7670/591 (100%)]\tBoneAge Loss: 30.3794\tGender Loss: 0.7693\t Loss: 61.5282\tCCC: 1.1378\n",
      "\n",
      "Test set: Avg BoneAge loss: 49.2186, Avg Gender loss: 0.6990, Avg loss: 0.0314 CCC: -0.3985\n",
      "\n",
      "Train Epoch: 6 [7670/591 (100%)]\tBoneAge Loss: 29.9753\tGender Loss: 0.7798\t Loss: 60.7303\tCCC: 1.4496\n",
      "\n",
      "Test set: Avg BoneAge loss: 44.4702, Avg Gender loss: 0.7238, Avg loss: 0.0284 CCC: -0.1258\n",
      "\n",
      "Train Epoch: 7 [7670/591 (100%)]\tBoneAge Loss: 29.8144\tGender Loss: 0.7948\t Loss: 60.4236\tCCC: 1.5462\n",
      "\n",
      "Test set: Avg BoneAge loss: 41.8303, Avg Gender loss: 0.7311, Avg loss: 0.0267 CCC: -0.2896\n",
      "\n",
      "Train Epoch: 8 [7670/591 (100%)]\tBoneAge Loss: 29.5529\tGender Loss: 0.7520\t Loss: 59.8578\tCCC: 1.6261\n",
      "\n",
      "Test set: Avg BoneAge loss: 47.5088, Avg Gender loss: 0.6940, Avg loss: 0.0303 CCC: -0.0419\n",
      "\n",
      "Train Epoch: 9 [7670/591 (100%)]\tBoneAge Loss: 29.3266\tGender Loss: 0.8076\t Loss: 59.4609\tCCC: 1.7222\n",
      "\n",
      "Test set: Avg BoneAge loss: 47.3320, Avg Gender loss: 0.6966, Avg loss: 0.0302 CCC: -0.0130\n",
      "\n",
      "Train Epoch: 10 [7670/591 (100%)]\tBoneAge Loss: 29.0525\tGender Loss: 0.7525\t Loss: 58.8575\tCCC: 1.8342\n",
      "\n",
      "Test set: Avg BoneAge loss: 46.0309, Avg Gender loss: 0.7653, Avg loss: 0.0294 CCC: -0.0407\n",
      "\n",
      "Train Epoch: 11 [7670/591 (100%)]\tBoneAge Loss: 28.8985\tGender Loss: 0.7653\t Loss: 58.5624\tCCC: 1.9578\n",
      "\n",
      "Test set: Avg BoneAge loss: 40.1472, Avg Gender loss: 0.7962, Avg loss: 0.0257 CCC: 0.0916\n",
      "\n",
      "Train Epoch: 12 [7670/591 (100%)]\tBoneAge Loss: 28.9898\tGender Loss: 0.7614\t Loss: 58.7409\tCCC: 1.9249\n",
      "\n",
      "Test set: Avg BoneAge loss: 44.7515, Avg Gender loss: 0.7659, Avg loss: 0.0286 CCC: 0.0350\n",
      "\n",
      "Train Epoch: 13 [7670/591 (100%)]\tBoneAge Loss: 28.5716\tGender Loss: 0.7542\t Loss: 57.8974\tCCC: 2.1882\n",
      "\n",
      "Test set: Avg BoneAge loss: 53.3024, Avg Gender loss: 0.9315, Avg loss: 0.0341 CCC: -0.0284\n",
      "\n",
      "Train Epoch: 14 [7670/591 (100%)]\tBoneAge Loss: 28.3899\tGender Loss: 0.7484\t Loss: 57.5282\tCCC: 2.2220\n",
      "\n",
      "Test set: Avg BoneAge loss: 41.6246, Avg Gender loss: 0.7035, Avg loss: 0.0266 CCC: 0.1230\n",
      "\n",
      "Train Epoch: 15 [7670/591 (100%)]\tBoneAge Loss: 28.0704\tGender Loss: 0.7413\t Loss: 56.8821\tCCC: 2.2887\n",
      "\n",
      "Test set: Avg BoneAge loss: 45.1515, Avg Gender loss: 1.0093, Avg loss: 0.0289 CCC: 0.1419\n",
      "\n",
      "Train Epoch: 16 [7670/591 (100%)]\tBoneAge Loss: 28.0531\tGender Loss: 0.7366\t Loss: 56.8428\tCCC: 2.3453\n",
      "\n",
      "Test set: Avg BoneAge loss: 47.9097, Avg Gender loss: 0.7124, Avg loss: 0.0306 CCC: 0.0216\n",
      "\n",
      "Train Epoch: 17 [7670/591 (100%)]\tBoneAge Loss: 27.4276\tGender Loss: 0.7401\t Loss: 55.5954\tCCC: 2.6540\n",
      "\n",
      "Test set: Avg BoneAge loss: 48.6959, Avg Gender loss: 1.2170, Avg loss: 0.0312 CCC: 0.0196\n",
      "\n",
      "Train Epoch: 18 [7670/591 (100%)]\tBoneAge Loss: 27.7187\tGender Loss: 0.7444\t Loss: 56.1819\tCCC: 2.5478\n",
      "\n",
      "Test set: Avg BoneAge loss: 43.7230, Avg Gender loss: 0.7387, Avg loss: 0.0279 CCC: 0.2883\n",
      "\n",
      "Train Epoch: 19 [7670/591 (100%)]\tBoneAge Loss: 27.2312\tGender Loss: 0.7732\t Loss: 55.2357\tCCC: 2.7303\n",
      "\n",
      "Test set: Avg BoneAge loss: 39.5075, Avg Gender loss: 0.6911, Avg loss: 0.0252 CCC: 0.2980\n",
      "\n",
      "Train Epoch: 20 [7670/591 (100%)]\tBoneAge Loss: 26.8517\tGender Loss: 0.7445\t Loss: 54.4479\tCCC: 2.8166\n",
      "\n",
      "Test set: Avg BoneAge loss: 42.0455, Avg Gender loss: 0.7376, Avg loss: 0.0269 CCC: 0.8282\n",
      "\n",
      "Train Epoch: 21 [7670/591 (100%)]\tBoneAge Loss: 26.9449\tGender Loss: 0.7385\t Loss: 54.6284\tCCC: 2.7422\n",
      "\n",
      "Test set: Avg BoneAge loss: 39.2037, Avg Gender loss: 0.7577, Avg loss: 0.0251 CCC: 0.5996\n",
      "\n",
      "Train Epoch: 22 [7670/591 (100%)]\tBoneAge Loss: 26.3094\tGender Loss: 0.7375\t Loss: 53.3563\tCCC: 3.0293\n",
      "\n",
      "Test set: Avg BoneAge loss: 39.1895, Avg Gender loss: 0.8050, Avg loss: 0.0251 CCC: 0.5729\n",
      "\n",
      "Train Epoch: 23 [7670/591 (100%)]\tBoneAge Loss: 26.1720\tGender Loss: 0.7505\t Loss: 53.0945\tCCC: 3.1069\n",
      "\n",
      "Test set: Avg BoneAge loss: 45.7072, Avg Gender loss: 0.7288, Avg loss: 0.0292 CCC: 0.4216\n",
      "\n",
      "Train Epoch: 24 [7670/591 (100%)]\tBoneAge Loss: 26.1262\tGender Loss: 0.7260\t Loss: 52.9785\tCCC: 3.1088\n",
      "\n",
      "Test set: Avg BoneAge loss: 37.2294, Avg Gender loss: 0.7126, Avg loss: 0.0238 CCC: 1.2304\n",
      "\n",
      "Train Epoch: 25 [7670/591 (100%)]\tBoneAge Loss: 25.4645\tGender Loss: 0.7311\t Loss: 51.6602\tCCC: 3.3153\n",
      "\n",
      "Test set: Avg BoneAge loss: 39.0876, Avg Gender loss: 0.7183, Avg loss: 0.0250 CCC: 1.0482\n",
      "\n",
      "Train Epoch: 26 [7670/591 (100%)]\tBoneAge Loss: 25.6640\tGender Loss: 0.7260\t Loss: 52.0540\tCCC: 3.2709\n",
      "\n",
      "Test set: Avg BoneAge loss: 36.8682, Avg Gender loss: 0.6982, Avg loss: 0.0236 CCC: 1.2942\n",
      "\n",
      "Train Epoch: 27 [7670/591 (100%)]\tBoneAge Loss: 24.9308\tGender Loss: 0.7216\t Loss: 50.5832\tCCC: 3.5554\n",
      "\n",
      "Test set: Avg BoneAge loss: 43.0707, Avg Gender loss: 0.7651, Avg loss: 0.0275 CCC: 0.9657\n",
      "\n",
      "Train Epoch: 28 [7670/591 (100%)]\tBoneAge Loss: 24.8121\tGender Loss: 0.7382\t Loss: 50.3624\tCCC: 3.6465\n",
      "\n",
      "Test set: Avg BoneAge loss: 39.1844, Avg Gender loss: 0.7261, Avg loss: 0.0250 CCC: 0.7363\n",
      "\n",
      "Train Epoch: 29 [7670/591 (100%)]\tBoneAge Loss: 24.6003\tGender Loss: 0.7244\t Loss: 49.9250\tCCC: 3.6709\n",
      "\n",
      "Test set: Avg BoneAge loss: 40.5099, Avg Gender loss: 0.8333, Avg loss: 0.0259 CCC: 1.1233\n",
      "\n",
      "Train Epoch: 30 [7670/591 (100%)]\tBoneAge Loss: 24.8820\tGender Loss: 0.7304\t Loss: 50.4945\tCCC: 3.4934\n",
      "\n",
      "Test set: Avg BoneAge loss: 40.5945, Avg Gender loss: 0.7051, Avg loss: 0.0259 CCC: 0.9255\n",
      "\n",
      "Train Epoch: 31 [7670/591 (100%)]\tBoneAge Loss: 23.6016\tGender Loss: 0.6900\t Loss: 47.8932\tCCC: 3.9636\n",
      "\n",
      "Test set: Avg BoneAge loss: 40.1200, Avg Gender loss: 0.7163, Avg loss: 0.0256 CCC: 1.0761\n",
      "\n",
      "Train Epoch: 32 [7670/591 (100%)]\tBoneAge Loss: 23.0577\tGender Loss: 0.6897\t Loss: 46.8051\tCCC: 4.1972\n",
      "\n",
      "Test set: Avg BoneAge loss: 38.5591, Avg Gender loss: 0.7144, Avg loss: 0.0246 CCC: 1.3620\n",
      "\n",
      "Train Epoch: 33 [7670/591 (100%)]\tBoneAge Loss: 22.9835\tGender Loss: 0.6911\t Loss: 46.6582\tCCC: 4.2243\n",
      "\n",
      "Test set: Avg BoneAge loss: 37.8534, Avg Gender loss: 0.7125, Avg loss: 0.0242 CCC: 1.6492\n",
      "\n",
      "Train Epoch: 34 [7670/591 (100%)]\tBoneAge Loss: 22.6882\tGender Loss: 0.6875\t Loss: 46.0639\tCCC: 4.3033\n",
      "\n",
      "Test set: Avg BoneAge loss: 39.2301, Avg Gender loss: 0.7175, Avg loss: 0.0251 CCC: 1.3738\n",
      "\n",
      "Train Epoch: 35 [7670/591 (100%)]\tBoneAge Loss: 22.7596\tGender Loss: 0.6901\t Loss: 46.2092\tCCC: 4.3042\n",
      "\n",
      "Test set: Avg BoneAge loss: 43.6358, Avg Gender loss: 0.7278, Avg loss: 0.0279 CCC: 1.1093\n",
      "\n",
      "Train Epoch: 36 [7670/591 (100%)]\tBoneAge Loss: 22.6864\tGender Loss: 0.6906\t Loss: 46.0633\tCCC: 4.3543\n",
      "\n",
      "Test set: Avg BoneAge loss: 38.1197, Avg Gender loss: 0.7145, Avg loss: 0.0244 CCC: 1.6657\n",
      "\n",
      "Train Epoch: 37 [7670/591 (100%)]\tBoneAge Loss: 22.5064\tGender Loss: 0.6925\t Loss: 45.7053\tCCC: 4.4332\n",
      "\n",
      "Test set: Avg BoneAge loss: 39.1566, Avg Gender loss: 0.7254, Avg loss: 0.0250 CCC: 1.5499\n",
      "\n",
      "Train Epoch: 38 [7670/591 (100%)]\tBoneAge Loss: 22.6574\tGender Loss: 0.6915\t Loss: 46.0063\tCCC: 4.3670\n",
      "\n",
      "Test set: Avg BoneAge loss: 38.2980, Avg Gender loss: 0.7105, Avg loss: 0.0245 CCC: 1.4876\n",
      "\n",
      "Train Epoch: 39 [7670/591 (100%)]\tBoneAge Loss: 22.5430\tGender Loss: 0.6916\t Loss: 45.7775\tCCC: 4.3555\n",
      "\n",
      "Test set: Avg BoneAge loss: 38.1510, Avg Gender loss: 0.7180, Avg loss: 0.0244 CCC: 1.6521\n",
      "\n",
      "Train Epoch: 40 [7670/591 (100%)]\tBoneAge Loss: 22.3457\tGender Loss: 0.6889\t Loss: 45.3802\tCCC: 4.4459\n",
      "\n",
      "Test set: Avg BoneAge loss: 38.3552, Avg Gender loss: 0.7189, Avg loss: 0.0245 CCC: 1.4978\n",
      "\n",
      "Train Epoch: 41 [7670/591 (100%)]\tBoneAge Loss: 22.3198\tGender Loss: 0.6891\t Loss: 45.3288\tCCC: 4.4075\n",
      "\n",
      "Test set: Avg BoneAge loss: 41.3794, Avg Gender loss: 0.7256, Avg loss: 0.0264 CCC: 1.4129\n",
      "\n",
      "Train Epoch: 42 [7670/591 (100%)]\tBoneAge Loss: 22.3020\tGender Loss: 0.6860\t Loss: 45.2900\tCCC: 4.4914\n",
      "\n",
      "Test set: Avg BoneAge loss: 36.7239, Avg Gender loss: 0.7164, Avg loss: 0.0235 CCC: 1.9977\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 [7670/591 (100%)]\tBoneAge Loss: 22.3466\tGender Loss: 0.6869\t Loss: 45.3800\tCCC: 4.4852\n",
      "\n",
      "Test set: Avg BoneAge loss: 37.2269, Avg Gender loss: 0.7150, Avg loss: 0.0238 CCC: 1.6468\n",
      "\n",
      "Train Epoch: 44 [7670/591 (100%)]\tBoneAge Loss: 22.1754\tGender Loss: 0.6884\t Loss: 45.0393\tCCC: 4.4603\n",
      "\n",
      "Test set: Avg BoneAge loss: 39.6905, Avg Gender loss: 0.7145, Avg loss: 0.0254 CCC: 1.4853\n",
      "\n",
      "Train Epoch: 45 [7670/591 (100%)]\tBoneAge Loss: 22.0891\tGender Loss: 0.6873\t Loss: 44.8654\tCCC: 4.5061\n",
      "\n",
      "Test set: Avg BoneAge loss: 37.6796, Avg Gender loss: 0.7135, Avg loss: 0.0241 CCC: 1.7270\n",
      "\n",
      "Train Epoch: 46 [7670/591 (100%)]\tBoneAge Loss: 22.0407\tGender Loss: 0.6875\t Loss: 44.7689\tCCC: 4.5500\n",
      "\n",
      "Test set: Avg BoneAge loss: 39.1904, Avg Gender loss: 0.7326, Avg loss: 0.0251 CCC: 1.7811\n",
      "\n",
      "Train Epoch: 47 [7670/591 (100%)]\tBoneAge Loss: 22.3725\tGender Loss: 0.6874\t Loss: 45.4325\tCCC: 4.4339\n",
      "\n",
      "Test set: Avg BoneAge loss: 37.2462, Avg Gender loss: 0.7182, Avg loss: 0.0238 CCC: 1.8752\n",
      "\n",
      "Train Epoch: 48 [7670/591 (100%)]\tBoneAge Loss: 22.0599\tGender Loss: 0.6869\t Loss: 44.8067\tCCC: 4.5136\n",
      "\n",
      "Test set: Avg BoneAge loss: 37.6731, Avg Gender loss: 0.7493, Avg loss: 0.0241 CCC: 2.0030\n",
      "\n",
      "Train Epoch: 49 [7670/591 (100%)]\tBoneAge Loss: 22.0887\tGender Loss: 0.6893\t Loss: 44.8667\tCCC: 4.5496\n",
      "\n",
      "Test set: Avg BoneAge loss: 37.0800, Avg Gender loss: 0.7732, Avg loss: 0.0237 CCC: 1.9578\n",
      "\n",
      "Train Epoch: 50 [7670/591 (100%)]\tBoneAge Loss: 21.9196\tGender Loss: 0.6875\t Loss: 44.5267\tCCC: 4.5727\n",
      "\n",
      "Test set: Avg BoneAge loss: 38.3849, Avg Gender loss: 0.7268, Avg loss: 0.0245 CCC: 1.8435\n",
      "\n",
      "Train Epoch: 51 [7670/591 (100%)]\tBoneAge Loss: 22.0251\tGender Loss: 0.6879\t Loss: 44.7381\tCCC: 4.5895\n",
      "\n",
      "Test set: Avg BoneAge loss: 37.4624, Avg Gender loss: 0.7369, Avg loss: 0.0240 CCC: 1.8859\n",
      "\n",
      "Train Epoch: 52 [7670/591 (100%)]\tBoneAge Loss: 21.6423\tGender Loss: 0.6843\t Loss: 43.9689\tCCC: 4.7957\n",
      "\n",
      "Test set: Avg BoneAge loss: 39.5639, Avg Gender loss: 0.7563, Avg loss: 0.0253 CCC: 1.7432\n",
      "\n",
      "Train Epoch: 53 [7670/591 (100%)]\tBoneAge Loss: 21.6057\tGender Loss: 0.6890\t Loss: 43.9004\tCCC: 4.7677\n",
      "\n",
      "Test set: Avg BoneAge loss: 38.3539, Avg Gender loss: 0.7146, Avg loss: 0.0245 CCC: 1.5528\n",
      "\n",
      "Train Epoch: 54 [7670/591 (100%)]\tBoneAge Loss: 22.0917\tGender Loss: 0.6870\t Loss: 44.8705\tCCC: 4.5063\n",
      "\n",
      "Test set: Avg BoneAge loss: 37.7392, Avg Gender loss: 0.7247, Avg loss: 0.0241 CCC: 1.8307\n",
      "\n",
      "Train Epoch: 55 [7670/591 (100%)]\tBoneAge Loss: 21.6469\tGender Loss: 0.6867\t Loss: 43.9806\tCCC: 4.7312\n",
      "\n",
      "Test set: Avg BoneAge loss: 39.7677, Avg Gender loss: 0.7198, Avg loss: 0.0254 CCC: 1.3542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 70 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
