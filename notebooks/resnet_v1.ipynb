{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TMP=\"/tmp\"\n",
      "env: JOBLIB_TEMP_FOLDER=\"/tmp\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline\n",
    "%env TMP=\"/tmp\"\n",
    "%env JOBLIB_TEMP_FOLDER=\"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary(input_size, model):\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            m_key = '%s-%i' % (class_name, module_idx+1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key]['input_shape'] = list(input[0].size())\n",
    "            summary[m_key]['input_shape'][0] = -1\n",
    "            summary[m_key]['output_shape'] = list(output.size())\n",
    "            summary[m_key]['output_shape'][0] = -1\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, 'weight'):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                if module.weight.requires_grad:\n",
    "                    summary[m_key]['trainable'] = True\n",
    "                else:\n",
    "                    summary[m_key]['trainable'] = False\n",
    "            if hasattr(module, 'bias'):\n",
    "                params +=  torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key]['nb_params'] = params\n",
    "\n",
    "        if not isinstance(module, nn.Sequential) and \\\n",
    "           not isinstance(module, nn.ModuleList) and \\\n",
    "           not (module == model):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    # check if there are multiple inputs to the network\n",
    "    if isinstance(input_size[0], (list, tuple)):\n",
    "        x = [Variable(torch.rand(1,*in_size)) for in_size in input_size]\n",
    "    else:\n",
    "        x = Variable(torch.rand(1,*input_size))\n",
    "\n",
    "    # create properties\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "    # make a forward pass\n",
    "    model(x)\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../data/boneage-training-dataset/'\n",
    "TRAIN_LABEL = '../data/train.csv'\n",
    "FILETYPE = '.png'\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BoneAgeDataset(Dataset):\n",
    "    \"\"\"Bone Age dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, labels, filetype, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.filetype = filetype\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, str(self.labels.iloc[idx]['id']) + self.filetype)\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "#         image = cv2.imread(img_name)[:,:,::-1]\n",
    "        boneage = self.labels.iloc[idx]['boneage'].astype(np.float32)\n",
    "        gender = self.labels.iloc[idx]['male'].astype(np.uint8)\n",
    "        \n",
    "        label = np.hstack((boneage, gender))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        sample = {'image': img, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale(1024),\n",
    "        transforms.CenterCrop(512),\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(1024),\n",
    "#         transforms.CenterCrop(512),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(TRAIN_LABEL)\n",
    "bins = xrange(20)\n",
    "labels['bins'] = np.digitize(labels['boneage'], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/software/miniconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=4)\n",
    "splits = []\n",
    "for train, test in skf.split(np.zeros(len(labels)), labels['bins']):\n",
    "    fold_label = {\n",
    "        'train': labels.loc[train, ('id', 'boneage', 'male')],\n",
    "        'val': labels.loc[test, ('id', 'boneage', 'male')]\n",
    "    }\n",
    "    splits.append(fold_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_label = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_datasets = {x: BoneAgeDataset(TRAIN_DIR, fold_label[x], FILETYPE, data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8, shuffle=True, num_workers=6, pin_memory=True)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([8, 3, 224, 224])\n",
      "0 -0.824975125545\n",
      "1 torch.Size([8, 3, 224, 224])\n",
      "1 -0.714101304884\n",
      "2 torch.Size([8, 3, 224, 224])\n",
      "2 -0.959426448647\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample in enumerate(dataloders['val']):\n",
    "    print(i_batch, sample['image'].size())\n",
    "    print(i_batch, sample['image'].mean())\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape=(3, 224, 224)):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.bn = nn.BatchNorm2d(input_shape[0])\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        num_ftrs = resnet.fc.in_features\n",
    "        resnet.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "        self.resnet = resnet\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(self.bn(x))\n",
    "        return x\n",
    "    \n",
    "model = Net([3, 224, 224])\n",
    "    \n",
    "# print(summary([3, 224, 224], model))\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ccc(x, y):\n",
    "#     print('X:', x)\n",
    "    mean_x = torch.mean(x)\n",
    "#     print('Mean x:', mean_x)\n",
    "    mean_y = torch.mean(y)\n",
    "#     print('Mean y:', mean_y)\n",
    "    xm = x.sub(mean_x)\n",
    "    ym = y.sub(mean_y)\n",
    "    xn = torch.norm(xm, 2)\n",
    "#     print('Xn:', xn)\n",
    "    yn = torch.norm(ym, 2)\n",
    "#     print('Yn:', yn)\n",
    "    xydot = ym.dot(xm.view(-1))\n",
    "#     print('XYdot:', xydot)\n",
    "\n",
    "    ccc_num = 2 * xydot / xm.size()[0]\n",
    "#     print('CCC num:', ccc_num)\n",
    "    ccc_den = xn + yn + torch.pow(mean_x.sub(mean_y), 2)\n",
    "#     print('CCC den:', ccc_den)\n",
    "\n",
    "    ccc = ccc_num / ccc_den\n",
    "    return ccc\n",
    "    \n",
    "\n",
    "def train(epoch, train_loader):\n",
    "    exp_lr_scheduler.step()\n",
    "    model.train()\n",
    "    train_boneage_loss = 0\n",
    "    train_gender_loss = 0\n",
    "    train_loss = 0\n",
    "    train_ccc = 0\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        boneage_loss = F.l1_loss(output[:,0], target[:,0])\n",
    "        train_boneage_loss += boneage_loss.data[0]\n",
    "        gender_loss = F.binary_cross_entropy(F.sigmoid(output[:,1]), target[:,1])\n",
    "        train_gender_loss += gender_loss.data[0]\n",
    "        loss = 2 * boneage_loss + gender_loss\n",
    "        train_loss += loss.data[0]\n",
    "        c = ccc(output[:,0], target[:,0])\n",
    "        train_ccc += c.data.cpu().numpy()[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % (1000 // len(target)) == 0:\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tBoneAge Loss: {:.4f}\\tGender Loss: {:.4f}\\t Loss: {:.4f}\\tCCC: {:.4f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader),\n",
    "        100. * batch_idx / len(train_loader), train_boneage_loss / len(train_loader),\n",
    "        train_gender_loss / len(train_loader), train_loss / len(train_loader),\n",
    "        train_ccc / len(train_loader)))\n",
    "\n",
    "def test(test_loader):\n",
    "    model.eval()\n",
    "    test_boneage_loss = 0\n",
    "    test_gender_loss = 0\n",
    "    test_loss = 0\n",
    "    test_ccc = 0\n",
    "    for sample in test_loader:\n",
    "        data = sample['image']\n",
    "        target = sample['label'].float()\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        boneage_loss = F.l1_loss(output[:,0], target[:,0])\n",
    "        test_boneage_loss += boneage_loss.data[0]\n",
    "        gender_loss = F.binary_cross_entropy(F.sigmoid(output[:,1]), target[:,1])\n",
    "        test_gender_loss += gender_loss.data[0]\n",
    "        loss = 2 * boneage_loss + gender_loss\n",
    "        test_loss += loss.data[0]\n",
    "        c = ccc(output[:,0], target[:,0])\n",
    "        test_ccc += c.data.cpu().numpy()[0]\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Avg BoneAge loss: {:.4f}, Avg Gender loss: {:.4f}, Avg loss: {:.4f} CCC: {:.4f}\\n'.format(\n",
    "        test_boneage_loss / len(test_loader), test_gender_loss / len(test_loader),\n",
    "        test_loss / len(test_loader), test_ccc / len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '../models/9-27-1540-resnet50-1fold-5.7889-2.56.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [5905/1182 (100%)]\tBoneAge Loss: 15.8622\tGender Loss: 0.7003\t Loss: 32.4247\tCCC: 8.1534\n",
      "\n",
      "Test set: Avg BoneAge loss: 36.4150, Avg Gender loss: 0.7005, Avg loss: 0.0233 CCC: 2.6063\n",
      "\n",
      "Train Epoch: 15 [5905/1182 (100%)]\tBoneAge Loss: 15.5458\tGender Loss: 0.6979\t Loss: 31.7895\tCCC: 8.3220\n",
      "\n",
      "Test set: Avg BoneAge loss: 26.9706, Avg Gender loss: 0.7039, Avg loss: 0.0173 CCC: 4.8107\n",
      "\n",
      "Train Epoch: 16 [5905/1182 (100%)]\tBoneAge Loss: 15.4276\tGender Loss: 0.6988\t Loss: 31.5541\tCCC: 8.3059\n",
      "\n",
      "Test set: Avg BoneAge loss: 45.4811, Avg Gender loss: 0.7010, Avg loss: 0.0290 CCC: 1.4971\n",
      "\n",
      "Train Epoch: 17 [5905/1182 (100%)]\tBoneAge Loss: 15.4484\tGender Loss: 0.6944\t Loss: 31.5911\tCCC: 8.3387\n",
      "\n",
      "Test set: Avg BoneAge loss: 39.7256, Avg Gender loss: 0.7599, Avg loss: 0.0254 CCC: 2.4498\n",
      "\n",
      "Train Epoch: 18 [5905/1182 (100%)]\tBoneAge Loss: 15.1520\tGender Loss: 0.6984\t Loss: 31.0025\tCCC: 8.5418\n",
      "\n",
      "Test set: Avg BoneAge loss: 30.2005, Avg Gender loss: 0.7014, Avg loss: 0.0193 CCC: 4.1793\n",
      "\n",
      "Train Epoch: 19 [5905/1182 (100%)]\tBoneAge Loss: 14.8312\tGender Loss: 0.6873\t Loss: 30.3497\tCCC: 8.5536\n",
      "\n",
      "Test set: Avg BoneAge loss: 34.3928, Avg Gender loss: 0.6982, Avg loss: 0.0220 CCC: 3.4960\n",
      "\n",
      "Train Epoch: 20 [5905/1182 (100%)]\tBoneAge Loss: 14.7231\tGender Loss: 0.6873\t Loss: 30.1334\tCCC: 8.6744\n",
      "\n",
      "Test set: Avg BoneAge loss: 32.3452, Avg Gender loss: 0.7345, Avg loss: 0.0207 CCC: 3.7795\n",
      "\n",
      "Train Epoch: 21 [5905/1182 (100%)]\tBoneAge Loss: 13.4250\tGender Loss: 0.6732\t Loss: 27.5233\tCCC: 9.3104\n",
      "\n",
      "Test set: Avg BoneAge loss: 29.7092, Avg Gender loss: 0.6896, Avg loss: 0.0190 CCC: 4.1810\n",
      "\n",
      "Train Epoch: 22 [5905/1182 (100%)]\tBoneAge Loss: 13.2313\tGender Loss: 0.6702\t Loss: 27.1329\tCCC: 9.4279\n",
      "\n",
      "Test set: Avg BoneAge loss: 29.0102, Avg Gender loss: 0.6902, Avg loss: 0.0186 CCC: 4.2744\n",
      "\n",
      "Train Epoch: 23 [5905/1182 (100%)]\tBoneAge Loss: 12.8530\tGender Loss: 0.6663\t Loss: 26.3724\tCCC: 9.5112\n",
      "\n",
      "Test set: Avg BoneAge loss: 29.0580, Avg Gender loss: 0.6880, Avg loss: 0.0186 CCC: 4.3776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 40 + 1):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            train(epoch, dataloders[phase])\n",
    "        if phase == 'val':\n",
    "            test(dataloders[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
